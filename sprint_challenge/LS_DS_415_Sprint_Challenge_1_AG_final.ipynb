{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_415_Sprint_Challenge_1_AG_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "toc-autonumbering": false
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bL5csS5KkXH"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zUCyQzsKkXK"
      },
      "source": [
        "# Sprint Challenge\n",
        "## *Data Science Unit 4 Sprint 1*\n",
        "\n",
        "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
        "\n",
        "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more manageable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
        "\n",
        "## Challenge Objectives\n",
        "Successfully complete all these objectives to earn full credit. \n",
        "\n",
        "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
        "\n",
        "Each unit test that you pass is 1 point. \n",
        "\n",
        "There are 5 total possible points in this sprint challenge. \n",
        "\n",
        "\n",
        "There are more details on each objective further down in the notebook.*\n",
        "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
        "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
        "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
        "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "3) Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section). \n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KM6-P_tKkXL"
      },
      "source": [
        "\n",
        "\n",
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "574padCgc64L"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "0y0jn4LzKkXM",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7bec125eb29f89460cf0c19ba9aa9a2f",
          "grade": false,
          "grade_id": "cell-395851cd95d17235",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "# Load reviews from URL\n",
        "data_url = 'https://raw.githubusercontent.com/LambdaSchool/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
        "\n",
        "# Import data into a DataFrame named df\n",
        "df = pd.read_json(data_url, lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WmblO74kKkXN",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "356579363f311da83f4ef7abaf3c9212",
          "grade": true,
          "grade_id": "cell-cb5006475e42b8f9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Visible Testing\n",
        "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
        "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jl2x2ERKkXN"
      },
      "source": [
        "## Part 1: Tokenize Function\n",
        "<a id=\"#p1\"></a>\n",
        "\n",
        "Complete the function `tokenize`. Your function should\n",
        "- accept one document at a time\n",
        "- return a list of tokens\n",
        "\n",
        "You are free to use any method you have learned this week."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S698x69YKkXO"
      },
      "source": [
        "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\n",
        "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\n",
        "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\n",
        "import re\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40MLxUI1c64N"
      },
      "source": [
        "# Create a clean_text function to reduce runtime in Code Grade, not having to run tokenize with mesy text\n",
        "def clean_data(doc):\n",
        "    \"\"\"\n",
        "    Takes in text and returns a clean text which mean\n",
        "    Non-alphabet are filtered out. \n",
        "    Replace multi white spaces with single white space\n",
        "    \"\"\"\n",
        "    non_alpha = '[^\\u4e00-\\u9fa5_a-zA-Z]' #[\\u4e00-\\u9fa5_] to detect chinese characters\n",
        "    multi_white_spaces = \"[ ]{2,}\"\n",
        "    \n",
        "    doc = re.sub(non_alpha, ' ', doc)\n",
        "    doc = re.sub(multi_white_spaces, \" \", doc)\n",
        "    \n",
        "    return doc.lower().strip()\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "pvmUOq9KKkXO",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4837ed2a1cc13057ba40203859d46ff6",
          "grade": false,
          "grade_id": "cell-3d570d5a1cd6cb64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "STOP_WORDS = nlp.Defaults.stop_words.union(['s', 'year', 't', 'dr'])\n",
        "def tokenize(doc):\n",
        "    \"\"\"\n",
        "    Takes a doc and returns a list of tokens in the form of lemmas\n",
        "    Stop words, punctation, and pronoun are filtered out.\n",
        "    \"\"\"\n",
        "    doc = nlp(doc)\n",
        "    \n",
        "    return [token.lemma_.strip() for token in doc if (token.text.lower() not in STOP_WORDS) and \n",
        "            (token.is_punct != True) and (token.pos_ != 'PRON')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "swQLwHuoKkXP",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2181ca9d36070260b1f75dcfd9e58965",
          "grade": true,
          "grade_id": "cell-02da164f6fbe730a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "'''Testing'''\n",
        "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeMz5w3-KkXP"
      },
      "source": [
        "## Part 2: Vector Representation\n",
        "<a id=\"#p2\"></a>\n",
        "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
        "2. Write a fake review and query for the 10 most similar reviews, print the text of the reviews. Do you notice any patterns?\n",
        "    - Given the size of the dataset, use `NearestNeighbors` model for this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "hkAoa1TwKkXQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d70a0a1a96cf8406c60b17e50b255a1a",
          "grade": false,
          "grade_id": "cell-0e96491cb529202c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "scrolled": false,
        "outputId": "09764836-a57f-464e-f2a9-0a526f4d629b"
      },
      "source": [
        "%%time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Create a vector representation of the reviews \n",
        "tfidf_vect = TfidfVectorizer(tokenizer=tokenize)\n",
        "\n",
        "# Name that doc-term matrix \"dtm\"\n",
        "dtm = tfidf_vect.fit_transform(df['clean_text'])\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "dtm = pd.DataFrame(data=dtm.toarray(), columns=tfidf_vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min, sys: 1.05 s, total: 2min 1s\n",
            "Wall time: 2min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "whuGseIFKkXQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "32b220e23c9aa1f602f08d1c2e879d0a",
          "grade": false,
          "grade_id": "cell-3d5bc610a8ec6b24",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Create and fit a NearestNeighbors model named \"nn\"\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# YOUR CODE HERE\n",
        "nn = NearestNeighbors(n_neighbors=10).fit(dtm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4P2QfYLKkXQ"
      },
      "source": [
        "#### Alex: \"instructor confirmed that unit test needs to be updated\" \n",
        "I uploaded this to colab to edit the testing cell and change 'sklearn.neighbors.unsupervised' to 'sklearn.neighbors._unsupervised'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "hP1rgTyxKkXR",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a0c054bd863f1a18f6f06f62b7f2664f",
          "grade": true,
          "grade_id": "cell-c43704dcff67e99b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "scrolled": true
      },
      "source": [
        "'''Testing.'''\n",
        "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
        "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8ya4-NZKkXR"
      },
      "source": [
        "# Create a fake review and find the 10 most similar reviews\n",
        "fake_review = \"\"\"Fake. This is the worst company I have ever seen. I could not believe what they did to me. \n",
        "I already called their office number to talk to their manager. They never answer the phone\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWufswawc64Q"
      },
      "source": [
        "def find_similarity(doc, df):\n",
        "    \"\"\"\n",
        "    function receive doc and process it to input into NearestNeighbors\n",
        "    Arg: \n",
        "    text -- the input document\n",
        "    df -- is the dataframe where all docs locate\n",
        "    return index of 10 documents from the dataframe that is similar to our input doc\n",
        "    \"\"\"\n",
        "    # Create a new df as a copy of df['clean_text']\n",
        "    df_new = df['clean_text'].copy()\n",
        "\n",
        "    # Attach fake review to the end of the new df\n",
        "    df_new.loc[len(df_new.index)] = doc\n",
        "\n",
        "    # Transform the new df to tfidf\n",
        "    dtm_new = tfidf_vect.fit_transform(df_new)\n",
        "\n",
        "    # View Feature Matrix as DataFrame\n",
        "    dtm_new = pd.DataFrame(data=dtm_new.toarray(), columns=tfidf_vect.get_feature_names())\n",
        "    \n",
        "    # Fit new dtm into NearestNeighbors\n",
        "    nn = NearestNeighbors(n_neighbors=10, algorithm='auto').fit(dtm_new)\n",
        "    doc = [dtm_new.iloc[-1].values]\n",
        "    \n",
        "    # Query Using kneighbors \n",
        "    neigh_dist, neigh_index = nn.kneighbors(doc)\n",
        "    \n",
        "    return neigh_index[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0U-YhS1c64R",
        "outputId": "29657d3e-3c2b-4f8e-8b52-8c3bea3372c5"
      },
      "source": [
        "# Display the nine docs that are similar to the fake review\n",
        "docs_index = find_similarity(fake_review, df)\n",
        "pd.DataFrame(data=df['clean_text'].loc[df.index.isin(docs_index[1:])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beware fake fake fake we also own a small busi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>well from the outside it looks like a pretty c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3180</th>\n",
              "      <td>this walmart has the rudest of employees i hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4406</th>\n",
              "      <td>probably the worst hvac service i have used al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4491</th>\n",
              "      <td>this is a update to my earlier review the mech...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5956</th>\n",
              "      <td>yesterday my two friends and i were at madison...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6019</th>\n",
              "      <td>i overall liked the atmosphere of this locatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8470</th>\n",
              "      <td>if could leave a star i would i was on hold fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9587</th>\n",
              "      <td>other than the pricing this company is awful t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             clean_text\n",
              "0     beware fake fake fake we also own a small busi...\n",
              "2943  well from the outside it looks like a pretty c...\n",
              "3180  this walmart has the rudest of employees i hav...\n",
              "4406  probably the worst hvac service i have used al...\n",
              "4491  this is a update to my earlier review the mech...\n",
              "5956  yesterday my two friends and i were at madison...\n",
              "6019  i overall liked the atmosphere of this locatio...\n",
              "8470  if could leave a star i would i was on hold fo...\n",
              "9587  other than the pricing this company is awful t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw7A7i4OKkXS"
      },
      "source": [
        "#### All the text are negative review of the companies. There is a pattern that using these word: worst, rudest, fake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSMyXCM0KkXS"
      },
      "source": [
        "## Part 3: Classification\n",
        "<a id=\"#p3\"></a>\n",
        "Your goal in this section will be to predict `stars` from the review dataset. \n",
        "\n",
        "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
        "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels). \n",
        "    - Use that Pipeline to predict a star rating for your fake review from Part 2. \n",
        "\n",
        "\n",
        "\n",
        "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`. \n",
        "    - Include 2 possible values for each parameter\n",
        "    - **Use `n_jobs` = 1** \n",
        "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
        "    \n",
        "    \n",
        "3. Train the entire pipeline with a GridSearch\n",
        "    - Name your GridSearch object as `gs`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzcVxS7QKkXT"
      },
      "source": [
        "# Assign X, Y for training\n",
        "X = df['clean_text']\n",
        "Y = df['stars']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "zR1WcHghKkXT",
        "jupyter": {
          "outputs_hidden": true
        },
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e1d18da8521d51d8bfc4b5b9d005fa34",
          "grade": false,
          "grade_id": "cell-e2beb0252d274bba",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "scrolled": true,
        "outputId": "f34db50d-c19f-4384-96d3-4cfc594cdfc0"
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Instantiate model\n",
        "tfid = TfidfVectorizer(tokenizer=tokenize)\n",
        "vect = CountVectorizer(tokenizer=tokenize)\n",
        "clf = KNeighborsClassifier('kd_tree')\n",
        "\n",
        "# Add feature union to add another vector representation method\n",
        "union = FeatureUnion(\n",
        "    transformer_list = [\n",
        "        (\"tfidf\", tfid),\n",
        "        (\"vect\", vect)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Instantiate pipeline\n",
        "pipe = Pipeline([('union', union),\n",
        "                 ('clf', clf)])\n",
        "\n",
        "# create a hyper-parameter dict\n",
        "params = {\n",
        "    \"union__tfidf__max_df\": [1, .9],\n",
        "    \"union__vect__max_df\": [1, .9],\n",
        "    \"clf__n_neighbors\": [5, 10]  \n",
        "}\n",
        "\n",
        "# Name the gridsearch instance \"gs\"\n",
        "gs = GridSearchCV(pipe, \n",
        "                  params, \n",
        "                  n_jobs=1, \n",
        "                  cv=3, \n",
        "                  verbose=1)\n",
        "\n",
        "# run the gridsearch\n",
        "gs.fit(X, Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('union',\n",
              "                                        FeatureUnion(transformer_list=[('tfidf',\n",
              "                                                                        TfidfVectorizer(tokenizer=<function tokenize at 0x7f527d70b940>)),\n",
              "                                                                       ('vect',\n",
              "                                                                        CountVectorizer(tokenizer=<function tokenize at 0x7f527d70b940>))])),\n",
              "                                       ('clf',\n",
              "                                        KNeighborsClassifier(n_neighbors='kd_tree'))]),\n",
              "             n_jobs=6,\n",
              "             param_grid={'clf__n_neighbors': [5, 10],\n",
              "                         'union__tfidf__max_df': [1, 0.9],\n",
              "                         'union__vect__max_df': [1, 0.9]},\n",
              "             verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpxKiYunc64S",
        "outputId": "3dbca5bf-1774-4ac3-fc57-99764cf30600"
      },
      "source": [
        "gs.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5051012899730285"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zp3IIVwMKkXT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b9e2378efb868f104a4eb39e4f25563c",
          "grade": true,
          "grade_id": "cell-d07134c6fe5d056e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Visible Testing\n",
        "prediction = gs.predict([\"I wish dogs knew how to speak English.\"])[0]\n",
        "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijbmK4L0KkXU"
      },
      "source": [
        "## Part 4: Topic Modeling\n",
        "\n",
        "Let's find out what those yelp reviews are saying! :D\n",
        "\n",
        "1. Estimate a LDA topic model of the review text\n",
        "    - Set num_topics to `5`\n",
        "    - Name your LDA model `lda`\n",
        "2. Create 1-2 visualizations of the results\n",
        "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
        "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
        "\n",
        "When you instantiate your LDA model, it should look like this: \n",
        "\n",
        "```python\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )\n",
        "\n",
        "```\n",
        "\n",
        "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSKagw20KkXU"
      },
      "source": [
        "## Note about  pyLDAvis\n",
        "\n",
        "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
        "\n",
        "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.** \n",
        "\n",
        "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAmlqL6mKkXU"
      },
      "source": [
        "from gensim import corpora\n",
        "# Due to limited computationalresources on CodeGrader, use the non-multicore version of LDA \n",
        "from gensim.models.ldamodel import LdaModel\n",
        "import gensim\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdnPkuTEKkXV"
      },
      "source": [
        "### 1. Estimate a LDA topic model of the review tex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "BtqrxaDxKkXV",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9514841e71735eaa255bccc53b257896",
          "grade": false,
          "grade_id": "cell-66331a185ff52f15",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "# Remember to read the LDA docs for more information on the various class attirbutes and methods available to you\n",
        "# in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html\n",
        "\n",
        "# don't change this value \n",
        "num_topics = 5\n",
        "\n",
        "# use tokenize function you created earlier to create tokens \n",
        "df['tokens'] = df['clean_text'].apply(tokenize)\n",
        "# create a id2word object (hint: use corpora.Dictionary)\n",
        "id2word = corpora.Dictionary(df['tokens'] )\n",
        "# create a corpus object (hint: id2word.doc2bow)\n",
        "corpus = [id2word.doc2bow(text) for text in df['tokens']]\n",
        "# instantiate an lda model\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au5DbMmRKkXV"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "huADFbEJKkXV",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6479db0fa59c99d3ae3201c1f10ebca1",
          "grade": true,
          "grade_id": "cell-5a3c181311134fa9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Visible Testing\n",
        "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSkPpaGLKkXV"
      },
      "source": [
        "#### 2. Create 1-2 visualizations of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "id": "EQ5eVeXlKkXW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "189591ed7b9e6e6146d59761fb418268",
          "grade": false,
          "grade_id": "cell-9b043e992fbd218c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "14875954-27c4-47aa-d357-37891eb29aff"
      },
      "source": [
        "# import pyLDAvis\n",
        "# import pyLDAvis.gensim_models\n",
        "# # Use pyLDAvis (or a ploting tool of your choice) to visualize your results \n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis = pyLDAvis.gensim_models.prepare(lda, corpus, id2word)\n",
        "# vis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el47781399920739284801196979540\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el47781399920739284801196979540_data = {\"mdsDat\": {\"x\": [-0.0934109763295443, -0.04888422534671612, 0.05829277412151458, 0.13307127756546447, -0.04906885001071864], \"y\": [0.007789453481285639, -0.016515794339913025, -0.05263508431063572, 0.03293858619166739, 0.028422838977595705], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [27.18919730747243, 20.001084636503183, 19.75707645726551, 19.39266368837263, 13.659977910386248]}, \"tinfo\": {\"Term\": [\"food\", \"great\", \"car\", \"burger\", \"order\", \"room\", \"chicken\", \"call\", \"nail\", \"good\", \"menu\", \"fry\", \"drink\", \"hair\", \"taco\", \"server\", \"tell\", \"delicious\", \"dr\", \"bar\", \"hotel\", \"sushi\", \"taste\", \"dish\", \"fresh\", \"company\", \"restaurant\", \"eat\", \"appointment\", \"beer\", \"yellowtail\", \"keg\", \"raman\", \"asia\", \"concoction\", \"cha\", \"satisfying\", \"dragon\", \"toasted\", \"hakka\", \"recline\", \"dim\", \"wonton\", \"gooey\", \"sammie\", \"alex\", \"hk\", \"tapioca\", \"mighty\", \"bao\", \"shawarma\", \"horribly\", \"marsala\", \"earl\", \"hangover\", \"volcano\", \"wheat\", \"lentil\", \"ginger\", \"mongolian\", \"thai\", \"tofu\", \"sum\", \"boba\", \"noodle\", \"pepperoni\", \"delish\", \"broth\", \"ayce\", \"curry\", \"cookie\", \"donut\", \"roll\", \"cream\", \"crust\", \"bagel\", \"sushi\", \"ice\", \"bowl\", \"pork\", \"pizza\", \"dumpling\", \"fresh\", \"vegan\", \"tea\", \"chicken\", \"rice\", \"topping\", \"beef\", \"milk\", \"taste\", \"sauce\", \"flavor\", \"try\", \"spicy\", \"place\", \"eat\", \"sweet\", \"good\", \"order\", \"cheese\", \"favorite\", \"fry\", \"like\", \"love\", \"delicious\", \"t\", \"food\", \"ve\", \"great\", \"time\", \"definitely\", \"come\", \"think\", \"get\", \"service\", \"amazing\", \"don\", \"go\", \"nice\", \"friendly\", \"look\", \"wi\", \"hibachi\", \"freezer\", \"fi\", \"grub\", \"removal\", \"roti\", \"heartbeat\", \"northern\", \"dolphin\", \"bisque\", \"dedicated\", \"dang\", \"humor\", \"knife\", \"tube\", \"msg\", \"scrumptious\", \"gabi\", \"torta\", \"ihop\", \"cola\", \"ami\", \"tai\", \"coca\", \"mug\", \"mule\", \"film\", \"chive\", \"xs\", \"ipa\", \"wagyu\", \"pancake\", \"scramble\", \"steak\", \"prime\", \"slider\", \"cappuccino\", \"server\", \"veal\", \"breakfast\", \"margarita\", \"egg\", \"lobster\", \"bread\", \"birthday\", \"come\", \"dinner\", \"food\", \"table\", \"party\", \"good\", \"waitress\", \"refill\", \"restaurant\", \"seat\", \"night\", \"meal\", \"coffee\", \"price\", \"rib\", \"serve\", \"like\", \"time\", \"nice\", \"order\", \"delicious\", \"service\", \"place\", \"ask\", \"menu\", \"t\", \"go\", \"get\", \"enjoy\", \"love\", \"eat\", \"chicken\", \"little\", \"look\", \"great\", \"drink\", \"m\", \"wait\", \"want\", \"try\", \"cirque\", \"urban\", \"google\", \"certificate\", \"instruct\", \"approve\", \"mission\", \"howard\", \"fe\", \"verify\", \"bachelorette\", \"queue\", \"hahaha\", \"pilot\", \"lebanese\", \"storage\", \"buckle\", \"po\", \"jr\", \"suzi\", \"recycle\", \"airline\", \"britney\", \"bye\", \"france\", \"thrifty\", \"ethic\", \"showroom\", \"tj\", \"authority\", \"scorpion\", \"talented\", \"hair\", \"shower\", \"campus\", \"stylist\", \"hire\", \"elevator\", \"tub\", \"duh\", \"unfriendly\", \"hotel\", \"unit\", \"acrylic\", \"miserable\", \"room\", \"gym\", \"bus\", \"roof\", \"bike\", \"stay\", \"shopping\", \"gate\", \"bath\", \"hop\", \"pool\", \"desk\", \"security\", \"bathroom\", \"wedding\", \"lobby\", \"walk\", \"casino\", \"bed\", \"floor\", \"t\", \"parking\", \"line\", \"cut\", \"people\", \"check\", \"know\", \"don\", \"leave\", \"work\", \"customer\", \"tell\", \"wait\", \"want\", \"time\", \"lot\", \"service\", \"m\", \"store\", \"minute\", \"ask\", \"say\", \"like\", \"great\", \"get\", \"come\", \"day\", \"place\", \"good\", \"need\", \"go\", \"ve\", \"staff\", \"promotion\", \"insurance\", \"physician\", \"ai\", \"therapist\", \"exam\", \"installer\", \"scott\", \"mercede\", \"kevin\", \"je\", \"cave\", \"tow\", \"pregnancy\", \"firm\", \"pt\", \"tan\", \"buyer\", \"bumper\", \"spider\", \"doctor\", \"sont\", \"vous\", \"des\", \"bra\", \"dr\", \"thread\", \"mani\", \"ou\", \"sur\", \"cox\", \"nail\", \"gel\", \"et\", \"car\", \"pedicure\", \"lash\", \"warranty\", \"toe\", \"est\", \"office\", \"robert\", \"pedi\", \"manicure\", \"un\", \"procedure\", \"company\", \"tech\", \"phone\", \"repair\", \"polish\", \"dealership\", \"refer\", \"call\", \"vet\", \"contact\", \"dentist\", \"appointment\", \"patient\", \"email\", \"client\", \"tire\", \"charge\", \"purchase\", \"card\", \"professional\", \"tell\", \"business\", \"fix\", \"say\", \"work\", \"customer\", \"go\", \"week\", \"t\", \"care\", \"day\", \"month\", \"need\", \"time\", \"money\", \"look\", \"service\", \"know\", \"take\", \"didn\", \"pay\", \"recommend\", \"get\", \"find\", \"come\", \"don\", \"want\", \"ask\", \"good\", \"place\", \"like\", \"new\", \"experience\", \"m\", \"yuk\", \"bowling\", \"layout\", \"josh\", \"mojito\", \"consultation\", \"coney\", \"brie\", \"enchilada\", \"sever\", \"calzone\", \"curly\", \"fog\", \"cesar\", \"ink\", \"chunky\", \"india\", \"br\", \"possibility\", \"alley\", \"lamp\", \"soothe\", \"pond\", \"jambalaya\", \"albeit\", \"lion\", \"summerlin\", \"aunt\", \"tomatillo\", \"jacuzzi\", \"chimichanga\", \"macaroon\", \"byob\", \"peoria\", \"port\", \"brewery\", \"tot\", \"carl\", \"asada\", \"burger\", \"taco\", \"carne\", \"toss\", \"great\", \"beer\", \"food\", \"unique\", \"drink\", \"fantastic\", \"bar\", \"dog\", \"atmosphere\", \"menu\", \"dish\", \"friendly\", \"order\", \"happy\", \"wine\", \"service\", \"hour\", \"selection\", \"place\", \"wait\", \"fry\", \"staff\", \"good\", \"restaurant\", \"go\", \"little\", \"love\", \"t\", \"get\", \"come\", \"amazing\", \"experience\", \"take\", \"price\", \"like\", \"time\"], \"Freq\": [4756.0, 4193.0, 739.0, 682.0, 3436.0, 1174.0, 1416.0, 861.0, 432.0, 6371.0, 1250.0, 1030.0, 1380.0, 430.0, 495.0, 804.0, 1585.0, 1225.0, 315.0, 1056.0, 520.0, 554.0, 1175.0, 855.0, 946.0, 430.0, 1646.0, 1542.0, 419.0, 597.0, 32.268618268287895, 29.517285723209156, 189.63042359291828, 22.933792116566, 18.25182906193508, 18.722006192080112, 16.18620050820503, 30.969950317722358, 19.620511265771118, 13.625394382971832, 15.03936455448128, 57.254622071214726, 15.774623678891587, 17.329665726708786, 13.962132606558306, 21.275765133614637, 13.345735783297926, 13.171619262241343, 13.745564347931506, 11.890093936113818, 42.09658554674135, 17.96744472698493, 11.387596997494585, 21.3103343999697, 20.56114165416581, 10.41981532704114, 16.08615239269788, 9.512131952386861, 29.75484267630263, 19.339978917880444, 213.90374075781583, 71.53296573529627, 52.09153932412133, 62.569539773665326, 305.0599553718062, 34.95734073798721, 59.40585329589299, 130.7723058947278, 71.78582807476022, 145.6959333265004, 138.6592582745517, 162.06611700464322, 470.5114660541099, 471.48208000997937, 132.82670688248956, 72.90987458430644, 434.1121961878485, 406.10053051258825, 240.48468416116233, 298.75022305745966, 643.9762458900404, 55.39731737984491, 689.7366371929583, 94.8561734284362, 286.15950730914494, 936.6968409824821, 374.52491883784444, 131.48641262015227, 337.6825501467834, 108.06832731026424, 717.1356771659298, 572.8926668109548, 482.81554505107823, 1363.8882885860767, 265.6708019461959, 2379.523685392953, 838.796205302475, 404.0819867315552, 2553.506734013136, 1535.4273983566202, 505.49610797226984, 393.3651551949493, 558.0977545228081, 1457.2969669325869, 952.7443334681893, 608.2150370691907, 2038.7704960502806, 1461.3560185130318, 798.1324761034274, 1248.6435890710482, 1248.4418735459346, 618.4348064599794, 827.3118007500153, 549.9469577943307, 687.2732589247537, 737.4726540800763, 520.9205607814569, 543.1321161722609, 587.6529289666586, 525.0816693093702, 508.18247151901824, 518.1367476819001, 22.665059044031757, 31.53643587050944, 22.035915065872445, 22.43966781231752, 24.241171198679687, 21.555445583279504, 20.779199893326574, 15.89754893150528, 20.325496753021213, 21.054249886485668, 25.7510087987411, 12.358805755517803, 12.157722303265569, 12.57947863591378, 19.380311741898563, 14.189703077721475, 17.432182541415717, 10.712297017963804, 12.24081795441058, 13.041869810565306, 14.729873052839736, 10.548601276641618, 17.24751683342601, 10.976605942608426, 10.210619619866874, 10.10676946182395, 11.45352215263728, 10.552850259370866, 13.421978567747676, 10.807721030471434, 35.24598858748497, 19.508799760868712, 126.08138122358822, 22.605696612963126, 331.27473801197095, 71.00191313878138, 60.99513151913036, 28.0826085091752, 480.6831142190491, 27.413058206950037, 293.1636452081698, 93.2400890683743, 251.75186543200715, 104.78029424104786, 268.04541781278937, 110.78418446102961, 1406.9612447299191, 321.8772911298433, 1631.1045914948932, 477.8651499886893, 192.1862840933358, 1817.1390740500467, 222.91167715837392, 75.43633345883075, 595.8029470184732, 255.10722260045472, 392.42234250260594, 331.4220109308542, 263.031290287172, 542.4322997973167, 115.87625473966567, 259.2031229770322, 885.2977229570733, 951.0260166586237, 487.95896284618607, 770.6757023380611, 382.0257426525186, 818.6068623720779, 973.3368424305314, 425.9827856851883, 381.6942625124281, 1135.8071008158663, 610.1333170330508, 558.3483144290764, 307.42599667729854, 456.3248605855668, 374.89584371658896, 359.2846589552353, 357.45215112566285, 393.2218970221799, 482.74758153876684, 342.25720271922364, 352.87956378244775, 344.26781235107734, 340.6807742667321, 342.82844242839144, 31.57003519702684, 22.91098933805194, 23.83719352171911, 13.465588751861242, 14.690360016401222, 14.124469763637547, 13.966839943203146, 11.687718605551341, 16.474744087771807, 13.1745202091441, 12.750237957617161, 10.723229167726618, 10.069013960798511, 11.4187751933346, 10.109820942380544, 14.249068466167966, 9.4648685512208, 9.440526966351564, 9.780869876626214, 10.75459848230654, 9.025884463990339, 24.499062769744377, 8.808656170569465, 8.41139631729482, 9.037719169422374, 9.024120186377642, 11.145932741925868, 10.277636563784426, 8.597195818052162, 12.162942760787187, 22.204533025419874, 23.500361251584426, 376.8811139656508, 93.57657943962931, 18.72579176995855, 70.21960766537633, 65.67747710130094, 57.6182626993333, 48.66411955323079, 16.935964379032306, 19.82753655986505, 385.63642546125413, 40.61771802035942, 28.86334956419816, 17.781605140144755, 769.3583617679509, 105.34041566013622, 69.07710103990307, 39.57310802089169, 61.37727758363782, 414.2182387413883, 67.20901912263173, 34.95959515724039, 33.229046634176626, 28.166320886120367, 171.8983690478576, 108.91655335241798, 45.52579501819607, 114.9872620660914, 84.62055019333322, 64.10899274061607, 395.5527491489717, 113.99136676691249, 101.57354680238119, 149.9014532308296, 1953.8113969204385, 196.30592729407627, 268.65677658276195, 214.25579951577762, 494.06780963621486, 362.6809006540414, 506.6396248086495, 514.04075076222, 346.05930159481346, 448.3319552251818, 371.99520867753665, 452.2391292991614, 466.3562854083249, 483.4225454870529, 861.5624048852444, 350.75902758235924, 755.6768546737151, 470.96488237253544, 292.76049498016533, 335.81664244381363, 405.863124456466, 416.79819449312436, 663.8052238166799, 684.2264261777523, 536.7301806557987, 642.4833254871727, 406.5637676821792, 695.0637171113655, 745.2648936658245, 373.33685079335794, 456.174187845304, 403.36072239293316, 375.06500012818157, 25.118571778184943, 113.6284700699089, 24.87132881974366, 27.153174586972092, 41.31361860340161, 25.86921677321497, 18.59433271635034, 14.21076565070055, 18.624213956280762, 23.150109752626864, 21.563603153648906, 15.401178766448478, 36.464543713300245, 15.329700690987593, 15.198568457094925, 16.405504107703866, 45.983107818297576, 18.294105104609336, 17.182576717880682, 12.88974784048719, 151.5288607488559, 18.888345210252606, 25.449317897484466, 33.50975458497224, 17.84970729787802, 294.6522712112684, 14.536285612740928, 29.727493839747066, 13.377278677561083, 13.694670312106616, 27.46475766073081, 389.24007363331884, 107.39038246112484, 65.96629288134473, 629.9832961640826, 145.95187710965243, 42.29059067366188, 70.64607685231672, 31.34025361416787, 31.480773236321717, 294.1125435131061, 42.38064095050507, 45.45860701816303, 66.63982708660279, 59.30745670665937, 57.85914011572459, 337.8616611274705, 92.71289634867598, 318.07517933896366, 175.91612783079916, 88.56174908694807, 74.49536464700873, 73.51913253871838, 582.2989988956415, 75.34831852839909, 106.44065393365881, 63.75058789734536, 291.7315653502552, 141.58620277460267, 110.72613102159434, 88.3806356575614, 119.13251540451687, 306.65478073468216, 203.3019346442358, 167.49803910645105, 235.7609995027718, 700.391302210133, 305.44808564205204, 230.39948828754382, 646.3494767794945, 617.2205671567275, 483.93981007442596, 943.5591691006047, 324.06915264980285, 1660.616463133436, 322.7186292077313, 574.3052938355413, 249.74572928000592, 500.2752893019445, 979.9521081289814, 257.4240248470352, 563.5006561319907, 774.7785142406993, 492.79072309385776, 449.4648524721221, 458.7385173005069, 340.9577070263786, 424.3101969971143, 540.1357295110499, 412.9757577772642, 560.3280143217916, 431.49810316675996, 414.8232430545969, 390.27856383465377, 539.8913788754417, 493.67120468594715, 445.15851014476056, 358.9646112261702, 364.07983608778494, 365.4036871364155, 49.87340100122656, 25.585848594696323, 27.249122378046415, 19.701205680293377, 14.18866701821479, 18.530483789524066, 13.870251504839468, 20.834054818573215, 64.63663988766469, 12.233841413796796, 10.773853741729159, 17.066926843399205, 11.545615615182752, 11.876052903367135, 11.567413752526118, 11.91463911430225, 12.253829150334345, 14.740862055022191, 13.587701151160742, 12.076733900408492, 8.138987787989095, 8.104834433104783, 7.928500205520946, 10.831166255033349, 8.361112670437265, 10.093111329478289, 27.28205443079982, 7.2735438660502245, 7.310988543472313, 11.838042413761073, 14.94828027980232, 18.657731085133257, 19.013469393446204, 18.900227683490762, 16.10293845548511, 31.15281819069031, 26.29888094709952, 15.038304862839176, 38.889014590419144, 409.61263365832747, 298.99470677331254, 42.596196201527135, 32.99299399563723, 1430.1098873561268, 256.36749891134815, 1342.050216442464, 88.2314399981091, 440.7222123035539, 164.92627278482615, 342.68024303890945, 159.46717414215516, 167.67638556402827, 357.3034458871003, 259.11260162679866, 365.5785491600864, 677.7023816686236, 239.9642013866495, 153.54565929891564, 686.7903202214131, 280.2146096374357, 174.66729534412386, 762.1342590778881, 347.7406293928917, 250.73598114431377, 316.6725264653053, 715.6949000491718, 300.55397813357825, 427.78895469360606, 268.9788757798868, 346.20843774429613, 609.6298210345418, 354.08460676374375, 402.05324018874467, 258.48312516752515, 259.57365432900434, 253.88648680320992, 261.6337576634783, 327.1758397371907, 336.6257078321381], \"Total\": [4756.0, 4193.0, 739.0, 682.0, 3436.0, 1174.0, 1416.0, 861.0, 432.0, 6371.0, 1250.0, 1030.0, 1380.0, 430.0, 495.0, 804.0, 1585.0, 1225.0, 315.0, 1056.0, 520.0, 554.0, 1175.0, 855.0, 946.0, 430.0, 1646.0, 1542.0, 419.0, 597.0, 33.205588794236256, 30.46105937802289, 198.03798143256498, 23.970941611080292, 19.08846975671351, 19.58562244930863, 16.998611975623394, 32.645943032219385, 20.701411912110192, 14.418714481230145, 15.971848141742367, 60.8428689132226, 16.766893014850655, 18.43334222520876, 14.859113431149941, 22.655305993705998, 14.267681743703264, 14.08562854751178, 14.738950482368974, 12.768005200336132, 45.25730737011251, 19.323670770075292, 12.256062519511492, 23.00771939578718, 22.20263476807488, 11.259361867672412, 17.429510309307872, 10.310813354914055, 32.270519152568845, 20.9991779539928, 234.984438755936, 78.34423105792186, 56.929981296268096, 68.5350776105933, 342.75829154131367, 38.075077559877045, 65.41159298332603, 146.56135927680597, 80.21033668336992, 166.81102796576585, 158.93223985138818, 189.79236131927155, 584.7924314830475, 588.0646718404851, 156.41301201071124, 83.35019753388192, 554.0794259948365, 519.3048968375538, 299.2819407655922, 378.6879536748694, 873.3077153119391, 62.71343296636929, 946.7298388839926, 112.24786396056342, 382.54638705436815, 1416.825605771839, 527.2834104733175, 163.1698478818184, 475.7590495428817, 131.39632476345844, 1175.856709845822, 918.3054743033214, 751.1493008209802, 2582.743674463973, 377.7272027715608, 5303.7297086986855, 1542.5324390383903, 649.3138166301209, 6371.496980653621, 3436.193422379055, 862.8533730349301, 632.9547005257782, 1030.7740026826539, 3778.7342635882915, 2247.2536226166617, 1225.8621227585709, 7398.635277954563, 4756.859346280796, 2004.3618592849182, 4193.50119189092, 4377.608111050922, 1412.363071894227, 3839.1376254776433, 1481.141014624919, 2676.5720902844223, 3773.325205587981, 1374.5732937945654, 1868.302307306022, 3025.3085576392245, 1753.9848990348528, 1413.0253739676348, 2007.871620112522, 23.505020269810448, 32.749379747008874, 22.90078727423023, 23.332288122217985, 25.205549087135463, 22.47639104959, 21.692095849149975, 16.77183128938761, 21.50187869967644, 22.36480168175023, 27.444670818662875, 13.209692935106702, 13.004006180766929, 13.471497952127107, 20.765575102066713, 15.23043096804443, 18.764590494900126, 11.53443062794343, 13.180760867065514, 14.054061880861449, 15.882498234011246, 11.375573409583753, 18.61483973315296, 11.850770090042015, 11.030405635794862, 10.937705968511606, 12.408259168547744, 11.444809177454095, 14.571662900687159, 11.742430770059816, 38.413367963069085, 21.463251428341724, 149.17834758510318, 25.623249432619346, 454.7456229007033, 86.9137887918314, 75.67300624776676, 33.02111002535808, 804.970331531078, 32.29951378291684, 469.7834525777961, 128.85420596520999, 424.70786599739944, 157.339109037644, 471.9536895312521, 173.22249269002089, 3839.1376254776433, 656.0441238359325, 4756.859346280796, 1064.0805887614483, 362.91369154214954, 6371.496980653621, 451.98604103347185, 115.44116991805689, 1646.8035595289757, 570.0663211988863, 1033.8970224693546, 862.5038689415701, 642.9268612894217, 1762.8318200570332, 214.7875570612788, 658.9959379357742, 3778.7342635882915, 4377.608111050922, 1753.9848990348528, 3436.193422379055, 1225.8621227585709, 3773.325205587981, 5303.7297086986855, 1488.5548102104647, 1250.373642055454, 7398.635277954563, 3025.3085576392245, 2676.5720902844223, 903.1275433378062, 2247.2536226166617, 1542.5324390383903, 1416.825605771839, 1401.9630346822416, 2007.871620112522, 4193.50119189092, 1380.7394776343695, 1795.68260443359, 1681.3074520387272, 1795.055796637253, 2582.743674463973, 32.47500527049897, 23.712620436929615, 25.217244712406263, 14.264643819783378, 15.627659146770704, 15.07351593283964, 14.914953294413648, 12.506494028959999, 17.64578258513028, 14.160115003530537, 13.760248749074975, 11.578438077488109, 10.874855151264237, 12.359735574915982, 10.944692574816484, 15.437796284869638, 10.266813633129729, 10.250175383373346, 10.645065577077137, 11.71283432902113, 9.8488554300582, 26.74226463840492, 9.619894939517105, 9.209867952914127, 9.895758739993196, 9.886654607054055, 12.217535067124059, 11.279553543783733, 9.445644854081209, 13.380781965330476, 24.439800573427732, 25.95220931678728, 430.95256109913436, 106.09538890953434, 20.714232235988888, 80.59856855613369, 75.39592688681002, 65.91303774032761, 57.20991509030908, 18.93801597722997, 22.367138733288172, 520.9138214378017, 47.8294636971519, 33.334610166423985, 19.950204402487138, 1174.446906414609, 135.95906951791525, 88.05521902815615, 48.09153035102733, 78.79234409588955, 661.4886029707459, 89.15199927338001, 42.99416997600182, 40.56953357992946, 33.63598512772358, 278.54163832826185, 163.96887341307954, 59.58537176110449, 180.86733539615756, 126.28591941227766, 91.80202312953762, 888.2367016771561, 188.5915641628042, 164.8786726231554, 274.92897564864506, 7398.635277954563, 400.06794039592455, 614.8297249861718, 472.3242672457649, 1491.9845190183657, 996.4886673810116, 1703.6146132443441, 1868.302307306022, 1054.2380709783822, 1548.2193015176172, 1179.2090903146036, 1585.7053809545594, 1681.3074520387272, 1795.055796637253, 4377.608111050922, 1101.0791379530392, 3773.325205587981, 1795.68260443359, 847.1447682949174, 1076.0472265779017, 1488.5548102104647, 1572.166922083481, 3778.7342635882915, 4193.50119189092, 2676.5720902844223, 3839.1376254776433, 1626.4002964635006, 5303.7297086986855, 6371.496980653621, 1420.7511967094954, 3025.3085576392245, 2004.3618592849182, 1635.40189776686, 25.926394431306406, 117.68930185323735, 25.784221455311293, 28.25423317532723, 43.264431594400136, 27.21587558861677, 19.599855835642302, 15.04005281508649, 19.72247999210234, 24.524251277725725, 22.879521448984008, 16.34217196169193, 38.70157058232258, 16.282038635546872, 16.14524924388675, 17.43577108495376, 48.894714501225444, 19.46194429586361, 18.280209847076435, 13.713583032240399, 161.6817991740069, 20.1930355023724, 27.252860796578965, 35.89646242509945, 19.122578224915237, 315.85445616520474, 15.594757491256015, 31.901675446843996, 14.380563896599266, 14.72315642472989, 29.57989432000122, 432.0417363096984, 117.91595826867584, 72.47836819514573, 739.5315211827658, 164.79892596686247, 46.361477992947634, 79.48959343039613, 34.109895089025464, 34.35650824704437, 353.77815744935424, 46.861399662884374, 50.507999592396494, 75.87667109610192, 67.07207335969117, 65.55708020218316, 430.6139196407131, 108.2694021088406, 411.05537237565585, 219.93675931722706, 104.5624398457254, 86.80175226657819, 86.25060141381795, 861.6682844237973, 89.25752723124978, 132.87550864009475, 74.27798829168037, 419.8309757739616, 187.48651432748727, 141.17614616439207, 109.50165914240493, 156.6095099006486, 499.51849685935815, 307.1044620069453, 247.43139699186705, 388.18606180213817, 1585.7053809545594, 546.6422173169716, 390.5075829344311, 1572.166922083481, 1548.2193015176172, 1179.2090903146036, 3025.3085576392245, 675.6442497261828, 7398.635277954563, 671.8045580103451, 1626.4002964635006, 477.41072112449154, 1420.7511967094954, 4377.608111050922, 507.14666485309715, 2007.871620112522, 3773.325205587981, 1703.6146132443441, 1461.8132164178928, 1530.666065925323, 869.1842739468075, 1426.3366104129202, 2676.5720902844223, 1602.2464849440864, 3839.1376254776433, 1868.302307306022, 1795.055796637253, 1488.5548102104647, 6371.496980653621, 5303.7297086986855, 3778.7342635882915, 1169.395339221107, 1452.038972766514, 1795.68260443359, 50.778122020036456, 26.585712564819346, 28.479190701217977, 20.603617566702958, 15.033574803096704, 19.668343114766504, 14.761489344098978, 22.23094306263308, 69.23428171226838, 13.114618852333548, 11.640386129226021, 18.453843148853696, 12.508532899114401, 12.86733105999593, 12.538866136794097, 12.937792222948254, 13.310975199102563, 16.078430393937925, 14.906854304120097, 13.27119810545578, 8.980889566876765, 8.955408821520617, 8.782972396642528, 12.01358860734917, 9.30289576216483, 11.231727191961546, 30.43382194802847, 8.122940347187122, 8.169234522203487, 13.23717775498894, 16.77817310020698, 21.014545527356635, 21.461378079201516, 21.407038477234686, 18.23636690897144, 36.33813975647525, 30.507341557625686, 17.12360416397434, 48.796575709302104, 682.5313889146635, 495.7586818043455, 56.304677526053666, 43.94136227792106, 4193.50119189092, 597.426625241373, 4756.859346280796, 165.0096748721143, 1380.7394776343695, 389.4943967103287, 1056.7765364853158, 391.5554809797329, 441.9128163435844, 1250.373642055454, 855.3179703089633, 1413.0253739676348, 3436.193422379055, 786.7958223769069, 419.72948319025124, 3773.325205587981, 1032.7642395479777, 511.836239276387, 5303.7297086986855, 1681.3074520387272, 1030.7740026826539, 1635.40189776686, 6371.496980653621, 1646.8035595289757, 3025.3085576392245, 1401.9630346822416, 2247.2536226166617, 7398.635277954563, 2676.5720902844223, 3839.1376254776433, 1374.5732937945654, 1452.038972766514, 1461.8132164178928, 1762.8318200570332, 3778.7342635882915, 4377.608111050922], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.3429, -8.432, -6.5719, -8.6844, -8.9127, -8.8873, -9.0329, -8.384, -8.8404, -9.2051, -9.1063, -7.7695, -9.0586, -8.9646, -9.1807, -8.7594, -9.2258, -9.2389, -9.1963, -9.3413, -8.077, -8.9284, -9.3845, -8.7578, -8.7936, -9.4733, -9.0391, -9.5644, -8.424, -8.8548, -6.4515, -7.5469, -7.864, -7.6807, -6.0965, -8.2629, -7.7326, -6.9436, -7.5433, -6.8355, -6.885, -6.729, -5.6632, -5.6611, -6.928, -7.5278, -5.7437, -5.8104, -6.3344, -6.1174, -5.3493, -7.8025, -5.2807, -7.2646, -6.1605, -4.9747, -5.8914, -6.9381, -5.9949, -7.1342, -5.2417, -5.4663, -5.6374, -4.5989, -6.2348, -4.0424, -5.085, -5.8154, -3.9718, -4.4804, -5.5915, -5.8423, -5.4925, -4.5327, -4.9577, -5.4065, -4.1969, -4.5299, -5.1347, -4.6872, -4.6874, -5.3898, -5.0988, -5.5072, -5.2843, -5.2138, -5.5614, -5.5197, -5.4409, -5.5535, -5.5862, -5.5668, -8.3892, -8.0588, -8.4173, -8.3991, -8.3219, -8.4393, -8.476, -8.7438, -8.4981, -8.4629, -8.2615, -8.9956, -9.012, -8.9779, -8.5457, -8.8575, -8.6517, -9.1386, -9.0052, -8.9418, -8.8201, -9.154, -8.6623, -9.1142, -9.1865, -9.1968, -9.0717, -9.1536, -8.9131, -9.1297, -7.9476, -8.5391, -6.673, -8.3918, -5.707, -7.2473, -7.3992, -8.1748, -5.3348, -8.199, -5.8292, -6.9748, -5.9815, -6.8581, -5.9188, -6.8024, -4.2608, -5.7358, -4.113, -5.3406, -6.2515, -4.005, -6.1032, -7.1867, -5.1201, -5.9683, -5.5376, -5.7066, -5.9377, -5.2139, -6.7575, -5.9524, -4.7241, -4.6524, -5.3197, -4.8627, -5.5645, -4.8024, -4.6292, -5.4556, -5.5654, -4.4749, -5.0963, -5.185, -5.7817, -5.3868, -5.5833, -5.6259, -5.631, -5.5356, -5.3305, -5.6744, -5.6439, -5.6686, -5.679, -5.6727, -8.0455, -8.3661, -8.3265, -8.8976, -8.8105, -8.8498, -8.861, -9.0392, -8.6959, -8.9194, -8.9522, -9.1253, -9.1882, -9.0624, -9.1842, -8.841, -9.2501, -9.2527, -9.2173, -9.1224, -9.2976, -8.2991, -9.322, -9.3681, -9.2963, -9.2978, -9.0866, -9.1677, -9.3463, -8.9993, -8.3974, -8.3407, -5.5658, -6.9589, -8.5678, -7.2461, -7.3129, -7.4439, -7.6128, -8.6683, -8.5106, -5.5428, -7.7935, -8.1351, -8.6195, -4.8521, -6.8405, -7.2625, -7.8196, -7.3807, -5.4713, -7.2899, -7.9435, -7.9943, -8.1596, -6.3508, -6.8071, -7.6794, -6.7529, -7.0595, -7.3371, -5.5174, -6.7616, -6.8769, -6.4877, -3.9202, -6.218, -5.9043, -6.1305, -5.295, -5.6042, -5.2699, -5.2554, -5.6511, -5.3922, -5.5788, -5.3835, -5.3528, -5.3168, -4.739, -5.6376, -4.8701, -5.3429, -5.8183, -5.6811, -5.4917, -5.4651, -4.9997, -4.9694, -5.2122, -5.0324, -5.49, -4.9537, -4.884, -5.5752, -5.3748, -5.4979, -5.5706, -8.2555, -6.7462, -8.2654, -8.1776, -7.7579, -8.226, -8.5562, -8.8251, -8.5546, -8.3371, -8.4081, -8.7446, -7.8827, -8.7493, -8.7579, -8.6815, -7.6508, -8.5725, -8.6352, -8.9227, -6.4583, -8.5405, -8.2424, -7.9672, -8.5971, -5.7933, -8.8024, -8.087, -8.8855, -8.8621, -8.1662, -5.5149, -6.8026, -7.2899, -5.0334, -6.4958, -7.7345, -7.2214, -8.0342, -8.0297, -5.7951, -7.7324, -7.6623, -7.2798, -7.3964, -7.4211, -5.6564, -6.9496, -5.7168, -6.3091, -6.9954, -7.1683, -7.1815, -5.1121, -7.157, -6.8115, -7.3241, -5.8033, -6.5262, -6.772, -6.9974, -6.6988, -5.7534, -6.1644, -6.3581, -6.0163, -4.9274, -5.7573, -6.0393, -5.0077, -5.0539, -5.2971, -4.6294, -5.6981, -4.0641, -5.7023, -5.1259, -5.9586, -5.2639, -4.5916, -5.9284, -5.1449, -4.8265, -5.279, -5.371, -5.3506, -5.6473, -5.4286, -5.1873, -5.4557, -5.1506, -5.4118, -5.4512, -5.5122, -5.1877, -5.2772, -5.3807, -5.5959, -5.5817, -5.5781, -7.2192, -7.8866, -7.8236, -8.148, -8.4762, -8.2092, -8.4989, -8.0921, -6.9599, -8.6245, -8.7515, -8.2915, -8.6824, -8.6541, -8.6805, -8.6509, -8.6228, -8.438, -8.5195, -8.6374, -9.032, -9.0362, -9.0582, -8.7462, -9.0051, -8.8168, -7.8224, -9.1444, -9.1393, -8.6573, -8.4241, -8.2024, -8.1835, -8.1895, -8.3497, -7.6898, -7.8591, -8.4181, -7.4679, -5.1134, -5.4282, -7.3769, -7.6324, -3.8632, -5.582, -3.9267, -6.6487, -5.0402, -6.0232, -5.2919, -6.0568, -6.0066, -5.2501, -5.5714, -5.2272, -4.61, -5.6482, -6.0947, -4.5966, -5.4931, -5.9658, -4.4925, -5.2772, -5.6043, -5.3708, -4.5554, -5.423, -5.07, -5.534, -5.2816, -4.7158, -5.2591, -5.1321, -5.5738, -5.5696, -5.5918, -5.5617, -5.3382, -5.3097], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2737, 1.2709, 1.259, 1.2581, 1.2575, 1.2573, 1.2534, 1.2496, 1.2487, 1.2458, 1.2422, 1.2416, 1.2413, 1.2406, 1.2401, 1.2395, 1.2356, 1.2353, 1.2326, 1.2311, 1.23, 1.2296, 1.2289, 1.2257, 1.2255, 1.2249, 1.2221, 1.2217, 1.2212, 1.22, 1.2084, 1.2114, 1.2135, 1.2113, 1.1858, 1.2169, 1.206, 1.1884, 1.1914, 1.167, 1.1659, 1.1444, 1.0849, 1.0814, 1.1389, 1.1685, 1.0583, 1.0565, 1.0836, 1.0652, 0.9977, 1.1783, 0.9856, 1.134, 1.012, 0.8885, 0.9603, 1.0865, 0.9595, 1.1069, 0.8079, 0.8305, 0.8604, 0.6638, 0.9504, 0.5008, 0.6931, 0.8281, 0.388, 0.4968, 0.7676, 0.8267, 0.6888, 0.3495, 0.4442, 0.6015, 0.0134, 0.1221, 0.3815, 0.0909, 0.0477, 0.4765, -0.2325, 0.3116, -0.0572, -0.3301, 0.332, 0.0669, -0.3363, 0.0963, 0.2797, -0.0522, 1.573, 1.5716, 1.5709, 1.5704, 1.5704, 1.5675, 1.5664, 1.5558, 1.5531, 1.549, 1.5457, 1.5428, 1.5421, 1.5409, 1.5403, 1.5386, 1.5357, 1.5354, 1.5354, 1.5346, 1.534, 1.5339, 1.5331, 1.5328, 1.5322, 1.5304, 1.5293, 1.5282, 1.5272, 1.5264, 1.5233, 1.5139, 1.4412, 1.4841, 1.2926, 1.4072, 1.3938, 1.4474, 1.0938, 1.4454, 1.1378, 1.2859, 1.0864, 1.2028, 1.0437, 1.1624, 0.6056, 0.8973, 0.5391, 0.8088, 0.9737, 0.3548, 0.9025, 1.1839, 0.5927, 0.8053, 0.6406, 0.6529, 0.7156, 0.4308, 0.9923, 0.6763, 0.1582, 0.0827, 0.33, 0.1145, 0.4435, 0.0813, -0.0861, 0.3582, 0.4228, -0.2646, 0.0083, 0.0421, 0.5318, 0.0151, 0.1949, 0.2373, 0.2428, -0.0211, -0.5524, 0.2146, -0.0176, 0.0235, -0.0525, -0.41, 1.5934, 1.5873, 1.5654, 1.564, 1.5598, 1.5566, 1.556, 1.5539, 1.553, 1.5495, 1.5454, 1.5449, 1.5447, 1.5425, 1.5423, 1.5415, 1.5403, 1.5394, 1.537, 1.5363, 1.5344, 1.534, 1.5336, 1.531, 1.531, 1.5304, 1.5299, 1.5286, 1.5275, 1.5262, 1.5257, 1.5224, 1.4876, 1.4961, 1.5207, 1.4838, 1.4837, 1.4872, 1.4599, 1.5099, 1.5011, 1.321, 1.4582, 1.4776, 1.5066, 1.1987, 1.3665, 1.3789, 1.4267, 1.3719, 1.1536, 1.3391, 1.4148, 1.4221, 1.4442, 1.139, 1.2126, 1.3525, 1.1687, 1.2213, 1.2626, 0.8127, 1.1182, 1.1372, 1.0151, 0.2901, 0.9097, 0.7937, 0.8312, 0.5165, 0.6109, 0.409, 0.3312, 0.5077, 0.3823, 0.4679, 0.3671, 0.3393, 0.3098, -0.0039, 0.4777, 0.0136, 0.2833, 0.5591, 0.4572, 0.3221, 0.2941, -0.1175, -0.1913, 0.0149, -0.166, 0.2353, -0.4105, -0.5242, 0.2852, -0.2702, 0.0184, 0.1491, 1.6086, 1.6052, 1.6042, 1.6005, 1.5941, 1.5895, 1.5876, 1.5836, 1.583, 1.5826, 1.581, 1.581, 1.5807, 1.58, 1.5799, 1.5794, 1.5789, 1.5784, 1.5784, 1.5783, 1.5754, 1.5735, 1.5718, 1.5715, 1.5714, 1.5708, 1.57, 1.5697, 1.568, 1.5679, 1.5661, 1.5359, 1.5468, 1.5461, 1.48, 1.5188, 1.5484, 1.5223, 1.5556, 1.5529, 1.4556, 1.5398, 1.5349, 1.5105, 1.5172, 1.5154, 1.3977, 1.4852, 1.3838, 1.4169, 1.4742, 1.4874, 1.4806, 1.2484, 1.4709, 1.4185, 1.4874, 1.2763, 1.3595, 1.3973, 1.426, 1.3668, 1.1524, 1.2278, 1.2501, 1.1416, 0.8231, 1.0583, 1.1126, 0.7514, 0.7206, 0.7496, 0.4752, 0.9056, 0.1462, 0.9071, 0.5993, 0.9923, 0.5965, 0.1435, 0.9622, 0.3696, 0.0571, 0.3999, 0.4609, 0.4353, 0.7045, 0.4279, 0.0398, 0.2845, -0.2842, 0.1748, 0.1753, 0.3016, -0.8279, -0.734, -0.4984, 0.4593, 0.2569, 0.0481, 1.9727, 1.9524, 1.9465, 1.9459, 1.9329, 1.9311, 1.9284, 1.9258, 1.922, 1.9212, 1.9133, 1.9126, 1.9106, 1.9105, 1.9101, 1.9083, 1.9079, 1.9038, 1.898, 1.8964, 1.8923, 1.8909, 1.8883, 1.8871, 1.884, 1.8838, 1.8814, 1.8803, 1.8797, 1.879, 1.8752, 1.8717, 1.8696, 1.8662, 1.8663, 1.8367, 1.8423, 1.8608, 1.7638, 1.4801, 1.485, 1.7117, 1.7041, 0.9149, 1.1447, 0.7253, 1.3647, 0.8487, 1.1313, 0.8645, 1.0924, 1.0216, 0.7381, 0.7965, 0.6387, 0.3673, 0.8032, 0.9851, 0.287, 0.6863, 0.9156, 0.0507, 0.4148, 0.577, 0.3489, -0.1956, 0.2897, 0.0346, 0.3397, 0.1203, -0.5055, -0.0321, -0.2657, 0.3196, 0.269, 0.2402, 0.083, -0.4559, -0.5746]}, \"token.table\": {\"Topic\": [2, 3, 4, 4, 1, 3, 4, 5, 1, 5, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 3, 4, 1, 2, 3, 4, 5, 5, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 5, 3, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 3, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 2, 5, 3, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 3, 1, 2, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 4, 5, 1, 3, 4, 5, 3, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 2, 2, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 3, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 1, 4, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 2, 1, 2, 3, 4, 5, 2, 3, 5, 5, 4, 3, 1, 3, 4, 5, 1, 2, 2, 5, 1, 5, 4, 5, 5, 3, 1, 2, 4, 2, 1, 2, 3, 4, 5, 5, 1, 3, 4, 3, 5, 1, 2, 3, 4, 5, 3, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 3, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 2, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 1, 5, 1, 2, 3, 4, 5, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 3, 4, 1, 2, 3, 4, 5, 4, 4, 1, 2, 3, 4, 5, 3, 1, 2, 4, 5, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 4, 1, 2, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 3, 5, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 3, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 3, 3, 4, 5, 1, 4, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 2, 1, 5], \"Freq\": [0.0899965526827047, 0.8699666759328122, 0.029998850894234902, 0.9556090173269158, 0.03739399088003515, 0.8974557811208436, 0.03739399088003515, 0.8599472900186899, 0.926935173854378, 0.04413977018354181, 0.9042137646236182, 0.379026714946395, 0.1869671127470701, 0.1287672332927292, 0.11712725740186103, 0.18769461124024933, 0.9132498718064741, 0.053720580694498477, 0.016673376677591372, 0.011909554769708123, 0.26677402684146195, 0.6955179985509544, 0.009527643815766498, 0.9287813183319198, 0.061479723861609194, 0.061479723861609194, 0.061479723861609194, 0.020493241287203062, 0.7992364102009195, 0.9594950575228348, 0.09875350171299092, 0.28618361720907576, 0.2727477666358797, 0.26199908617732287, 0.07994331091051646, 0.26702099517352706, 0.2534436564358901, 0.07467536305700333, 0.022628897896061616, 0.38016548465383515, 0.8617569132369681, 0.8968085744982562, 0.07473404787485469, 0.8976399174612594, 0.012467221075850824, 0.012467221075850824, 0.012467221075850824, 0.08727054753095577, 0.9447503629521172, 0.8758227593920871, 0.08398300432526863, 0.011997572046466946, 0.023995144092933893, 0.011997572046466946, 0.9398492412647268, 0.1968249604516936, 0.22805199744643342, 0.23656846208136248, 0.015140381573207198, 0.32457192997562934, 0.024649038619825776, 0.024649038619825776, 0.8134182744542506, 0.04929807723965155, 0.07394711585947733, 0.08293371474260502, 0.2266854869631204, 0.6358251463599719, 0.016586742948521006, 0.03870240021321568, 0.02426026323697031, 0.16982184265879216, 0.6186367125427429, 0.09704105294788123, 0.09097598713863865, 0.7104436590849019, 0.1849675798800928, 0.014713330217734655, 0.014713330217734655, 0.07566855540549251, 0.27785838961049397, 0.2259691722735945, 0.05356306305744462, 0.013390765764361155, 0.42850450445955696, 0.012691588395733085, 0.012691588395733085, 0.7741868921397181, 0.012691588395733085, 0.19037382593599628, 0.11545844704930847, 0.640794381123662, 0.06927506822958508, 0.13277721410670473, 0.04618337881972339, 0.03643694641511174, 0.9473606067929052, 0.03643694641511174, 0.9192373044057404, 0.058364273295602564, 0.014591068323900641, 0.8019194188130989, 0.08687460370475239, 0.06682661823442491, 0.003341330911721246, 0.040095970940654944, 0.977968897264224, 0.9329268860507349, 0.052294203649645814, 0.9412956656936247, 0.33689746160882855, 0.5678523252274594, 0.016950815678431624, 0.012713111758823718, 0.0635655587941186, 0.17880578708993503, 0.6236916144922734, 0.1447475419299474, 0.01277184193499536, 0.03831552580498608, 0.13759647669110603, 0.8530981554848573, 0.04498234722578422, 0.9446292917414685, 0.9355611528593033, 0.8938235879252749, 0.06140772741471355, 0.013646161647714122, 0.013646161647714122, 0.013646161647714122, 0.876610828013681, 0.9299674425082609, 0.29302681641943634, 0.07765210635115063, 0.01758160898516618, 0.010255938574680271, 0.6007049736598445, 0.01135651027885405, 0.05678255139427025, 0.7835992092409294, 0.1135651027885405, 0.0227130205577081, 0.1207371072141868, 0.09146750546529303, 0.1664708599468333, 0.5579517833382874, 0.06219790371639926, 0.9248818990724207, 0.8686335179722844, 0.04659533028632081, 0.04659533028632081, 0.04659533028632081, 0.8853112754400955, 0.060348049173903046, 0.05222427332356994, 0.16943875344980472, 0.675433934984838, 0.041779418658855955, 0.9449858344803377, 0.048275986703605694, 0.9172437473685082, 0.048275986703605694, 0.09085097374667883, 0.8479424216356691, 0.030283657915559613, 0.030283657915559613, 0.030283657915559613, 0.017578696279515603, 0.020283111091748775, 0.09735893324039412, 0.8518906658534485, 0.012169866655049265, 0.12124572857253878, 0.08083048571502585, 0.07274743714352326, 0.6749345557204659, 0.04445676714326422, 0.06102965440042257, 0.09080021752257993, 0.26346948363109257, 0.4807945944228413, 0.10419697092755073, 0.058398920602466375, 0.058398920602466375, 0.8759838090369956, 0.08880256880409923, 0.05328154128245954, 0.08880256880409923, 0.017760513760819843, 0.7637020917152534, 0.14316653090957923, 0.13256160269405484, 0.6044809082848901, 0.01590739232328658, 0.10074681804748167, 0.917870649945543, 0.9113441712418037, 0.9325943308715798, 0.9700993700443101, 0.0800771147645053, 0.13212723936143372, 0.13813302296877164, 0.6145918558175781, 0.03603470164402738, 0.15052855582816865, 0.18966598034349252, 0.36427910510416817, 0.18565188552140802, 0.10938408390180256, 0.5852674576953373, 0.28046480150944875, 0.02086101829409123, 0.00579472730391423, 0.10778192785280469, 0.661337567716779, 0.2533833370441021, 0.013410260177821558, 0.009881244341552728, 0.0628164818855852, 0.05960124466636142, 0.8940186699954213, 0.8921425158268627, 0.9275152818357327, 0.9853732042060521, 0.04566140859562311, 0.009132281719124622, 0.11871966234862008, 0.8036407912829666, 0.018264563438249243, 0.9065849734074073, 0.15087252662839704, 0.40906674745637545, 0.28152502391484396, 0.119764789179243, 0.038884671811442534, 0.9669842217125215, 0.21541296006472532, 0.36648855478968384, 0.16722505485072994, 0.14586609145858062, 0.10471101565419538, 0.013933595098379908, 0.03483398774594977, 0.13933595098379908, 0.7849258572087349, 0.027867190196759817, 0.9429776314923992, 0.9484137862821146, 0.9660193484084214, 0.015051682740249595, 0.03010336548049919, 0.12793930329212155, 0.7977391852332285, 0.022577524110374392, 0.8745865541816683, 0.05033591678743415, 0.018875968795287804, 0.025167958393717074, 0.03775193759057561, 0.03380674687954594, 0.9127821657477405, 0.8009323167227442, 0.11393304717712072, 0.018705425655945192, 0.023806905380293883, 0.040811837794789516, 0.8503128882326753, 0.07671995984054213, 0.025573319946847375, 0.01917998996013553, 0.03196664993355922, 0.054189254343050886, 0.921217323831865, 0.875241893659232, 0.07793249738061654, 0.011989614981633315, 0.029974037454083287, 0.09582694106424544, 0.0983710191455971, 0.31546568208760445, 0.4104445971247327, 0.07971444654901834, 0.17149235306568147, 0.20536738577001362, 0.4530785624204424, 0.11009385628907946, 0.06139849677660201, 0.9227925481724343, 0.18691585377906522, 0.1045253129685562, 0.25024589634236694, 0.3529266449644192, 0.10514016775072418, 0.011520504758116917, 0.011520504758116917, 0.11520504758116917, 0.8525173521006519, 0.9084238414133182, 0.4375645415106708, 0.2074537389362889, 0.1571833789892701, 0.07646758977856383, 0.12036565057736899, 0.4959774747194334, 0.31161742655069663, 0.02365682034023613, 0.01468354365945691, 0.15417720842429755, 0.9019807851956702, 0.03057561983714136, 0.01528780991857068, 0.03057561983714136, 0.03057561983714136, 0.026925877315716332, 0.013462938657858166, 0.8616280741029226, 0.09424057060500717, 0.9471685426089951, 0.027857898312029266, 0.0182961554687409, 0.08538205885412421, 0.6647603153642528, 0.21345514713531052, 0.024394873958321205, 0.21363248802561058, 0.1757404870914044, 0.1992596600850496, 0.2998694556689763, 0.11106276135888012, 0.9368394524803965, 0.032871559736154264, 0.016435779868077132, 0.23016744531921604, 0.49082064498534816, 0.047252919237719855, 0.00914572630407481, 0.22102171901514125, 0.41738863486177225, 0.23266201214983942, 0.035074675198468255, 0.011691558399489418, 0.30281136254677593, 0.006184988076015714, 0.018554964228047144, 0.024739952304062857, 0.9401181875543886, 0.012369976152031429, 0.06384791227400546, 0.010215665963840874, 0.23240640067737986, 0.28603864698754444, 0.4060727220626747, 0.9389754623729164, 0.04471311725585316, 0.2906381894817509, 0.12952935884822048, 0.2751160762313443, 0.23069071761811166, 0.07386384926055548, 0.8535643841191332, 0.03688241165946871, 0.05795807546487941, 0.010537831902705347, 0.04215132761082139, 0.006332030341702441, 0.04749022756276831, 0.009498045512553661, 0.93397447540111, 0.0031660151708512206, 0.9495820037854337, 0.0306316775414656, 0.2600056026608852, 0.2476933596379463, 0.13833167161066592, 0.03476398030006264, 0.3193940690068255, 0.05280384181755603, 0.8976653108984524, 0.8770050912297259, 0.07972773556633872, 0.015945547113267743, 0.015945547113267743, 0.9127371400333227, 0.043463673334920135, 0.5439107656776605, 0.24310671886665397, 0.062235320029863414, 0.02204167584390996, 0.1290086321452377, 0.34141114777678233, 0.5933490292396493, 0.021191036758558903, 0.014127357839039269, 0.030609275317918416, 0.09102903167105916, 0.879947306153572, 0.030343010557019722, 0.021250048832659452, 0.021250048832659452, 0.16291704105038915, 0.7862518068083998, 0.01416669922177297, 0.014443711630546158, 0.04333113489163847, 0.9388412559855003, 0.36207510490873024, 0.3399298385534562, 0.12954980817835302, 0.06643579906582206, 0.1018682252342605, 0.029106566732841028, 0.9023035687180718, 0.029106566732841028, 0.027594440242019007, 0.013797220121009503, 0.9106165279866273, 0.041391660363028514, 0.9003452774692415, 0.0367432602616047, 0.9553247668017223, 0.1797472415652362, 0.14875633784709202, 0.24172904900152453, 0.25068197674232173, 0.1790585548159441, 0.3389008959175602, 0.07702293089035459, 0.048781189563891235, 0.11296696530585339, 0.4236261198969502, 0.6208975139509124, 0.09479351358029198, 0.08531416222226278, 0.04265708111113139, 0.1548294055144769, 0.056670765106370424, 0.9067322417019268, 0.9428993798105328, 0.9611344173103074, 0.23654288123666936, 0.1554068006014002, 0.2009678304965898, 0.25776308694127825, 0.1491655636294564, 0.9290658678236022, 0.033290006566102426, 0.07426232233976696, 0.22278696701930084, 0.5889770392464275, 0.07938386181147501, 0.6430146436561915, 0.22765114713293738, 0.03594491796835853, 0.009319052806611472, 0.0852027685175906, 0.05455954565942066, 0.221875485681644, 0.5455954565942066, 0.10184448523091856, 0.07638336392318892, 0.9593451203897457, 0.30713542142933015, 0.34287328703027886, 0.05171479375196113, 0.01597692815101238, 0.282118915508666, 0.9094805397414315, 0.9606656634357778, 0.7288246040849137, 0.13731478047976634, 0.029575491180257367, 0.014787745590128683, 0.08978274108292415, 0.3595122984759902, 0.11677072686720154, 0.17904844786304236, 0.08563186636928113, 0.2590187032327016, 0.5413407774621498, 0.19402895249539423, 0.013582026674677596, 0.007761158099815768, 0.24350633538171973, 0.9104178522792371, 0.023258967449730345, 0.04651793489946069, 0.814063860740562, 0.09303586979892138, 0.023258967449730345, 0.033922465277226116, 0.016961232638613058, 0.042403081596532645, 0.9074259461657986, 0.008480616319306529, 0.2566715847085579, 0.2084756102873003, 0.20062975398616534, 0.2017505906006132, 0.13225872050484644, 0.9296410714115176, 0.030988035713717253, 0.030988035713717253, 0.19436034004374123, 0.2016323255555819, 0.15072842697269728, 0.31203428741716277, 0.1414731726849001, 0.40084771408586584, 0.28517631029523033, 0.11692699569066956, 0.0847524532522974, 0.11237547505304617, 0.92224186977614, 0.9517296704581129, 0.0396554029357547, 0.2978418135221287, 0.11517821932040687, 0.16310952798169417, 0.08298554932401984, 0.3410038377395069, 0.9521712824835561, 0.022065464338917762, 0.029420619118557017, 0.7722912518621217, 0.12503763125386733, 0.05148608345747478, 0.9195524777943794, 0.03016573324647104, 0.020883969170633798, 0.8748062641476602, 0.05104970241710484, 0.02320441018959311, 0.9709603458910837, 0.9458336913326996, 0.04503969958727141, 0.25546653182877843, 0.10294919939368684, 0.08642648837988524, 0.24911164297731628, 0.3050346648701832, 0.9539805000378232, 0.9771177422962547, 0.026526631909473693, 0.053053263818947385, 0.8753788530126319, 0.039789947864210536, 0.013263315954736846, 0.911150124703144, 0.029730064280941076, 0.08919019284282323, 0.8324417998663501, 0.029730064280941076, 0.029730064280941076, 0.9315000350696756, 0.05175000194831531, 0.044153176693443236, 0.15933537676329515, 0.7410054871160474, 0.021116736679472854, 0.03263495668645804, 0.1142564735313129, 0.10554199673655174, 0.2314177726608795, 0.27789498223293896, 0.2711170558370136, 0.9595015175486301, 0.9650003322716862, 0.7818143107689639, 0.07124908743461002, 0.04814127529365541, 0.04043867124667055, 0.057769530352386494, 0.9444358046820721, 0.06296238697880481, 0.9015117089850073, 0.9570243329089505, 0.9693948853158673, 0.9598366498222223, 0.00849694903660007, 0.01699389807320014, 0.968652190172408, 0.00849694903660007, 0.05206520818280802, 0.9111411431991404, 0.07554480407450233, 0.9065376488940279, 0.08323907474143587, 0.9156298221557945, 0.9615585732007055, 0.04370720787275934, 0.9707033211644128, 0.9394023857902569, 0.9848639742859522, 0.04077596452081108, 0.9378471839786549, 0.9149758630142156, 0.1573125740507848, 0.16553039508328848, 0.2976025188199548, 0.28938469778745113, 0.09039603135754053, 0.890780355378773, 0.021569631584051677, 0.06470889475215502, 0.9059245265301704, 0.035113357345411954, 0.9480606483261227, 0.12995167199080337, 0.14038574784407953, 0.32819911320305084, 0.3130222755982855, 0.08821536857769863, 0.9136848688660106, 0.9698555929376877, 0.3855788468746227, 0.23420540801924578, 0.17572021573421379, 0.11776430120741736, 0.08653691347151793, 0.17403192404597315, 0.15776725824728408, 0.4375195099847362, 0.13824965928885719, 0.09270859505252775, 0.8903350151842111, 0.341663787239987, 0.25464294790120123, 0.10841940638930696, 0.10271312184250132, 0.19187381788633928, 0.04357202448965405, 0.1851811040810297, 0.6971523918344648, 0.032679018367240534, 0.04357202448965405, 0.22880515988804068, 0.6673483830067853, 0.019067096657336722, 0.006355698885778908, 0.0826240855151258, 0.25798462153221285, 0.19572964529374448, 0.17281981403798813, 0.2808944527879692, 0.09263540464284091, 0.3305847758379058, 0.1525775888482642, 0.3187781767008377, 0.07265599468964962, 0.1253315908396456, 0.42407318444561853, 0.20291434638741035, 0.139726106942208, 0.07920779310736632, 0.15396571019746486, 0.21106179848500983, 0.19658262497416482, 0.26229579706184597, 0.20326532044070866, 0.12697121386433308, 0.04758608739352487, 0.04758608739352487, 0.9041356604769726, 0.031346316016105324, 0.9403894804831598, 0.031346316016105324, 0.02635856279813451, 0.013179281399067254, 0.05271712559626902, 0.8830118537375061, 0.013179281399067254, 0.7217459399432374, 0.24058197998107916, 0.023282127094943143, 0.8975150039001631, 0.344346281442733, 0.3837663944698472, 0.027825962136786505, 0.019710056513557107, 0.22376711218332482, 0.33749911690899537, 0.30550867928728964, 0.04878541737310123, 0.022393306335194006, 0.2855146557737236, 0.9633676904531454, 0.949864104418227, 0.8219407977690636, 0.0684950664807553, 0.022831688826918436, 0.03805281471153072, 0.03805281471153072, 0.11709523233539795, 0.18958275711445383, 0.3122539528943945, 0.1886534298736967, 0.1923707388367252, 0.05012479971760754, 0.05012479971760754, 0.9022463949169357, 0.93865530274531, 0.9312489001030013, 0.1045062576037097, 0.10647807378491177, 0.197181618120207, 0.506756758568932, 0.084788095791689, 0.9047973230965132, 0.04762091174192175, 0.1089208886585525, 0.07750140154550851, 0.20527398247188738, 0.5236581185507332, 0.0837852989681173, 0.9059616837692402, 0.9142684973237393, 0.8865063060483636, 0.030089685573065263, 0.00925836479171239, 0.04629182395856195, 0.9003759759940299, 0.013887547187568584, 0.10698565684972626, 0.1970788415652852, 0.2625371710851835, 0.35192650279515214, 0.080943095642885, 0.2266128409375286, 0.09748627874293683, 0.22917826932550062, 0.3069962637606519, 0.14024341854247052, 0.29931842645218115, 0.27822360401650365, 0.16077675478002873, 0.11972737058087247, 0.1419624536887488, 0.1799018625237536, 0.3791480113403839, 0.26114786495383585, 0.045459072788260314, 0.13347557542084942, 0.8898398887113061, 0.0846077271233701, 0.002917507831840348, 0.011670031327361392, 0.011670031327361392, 0.9301512802367805, 0.01978641092618076, 0.06218586291085382, 0.05935923277854228, 0.8310292588995919, 0.028266301323115372, 0.44671524891553976, 0.22437619342923854, 0.07566512359481456, 0.05616680328384311, 0.19731136075878564, 0.9039979303644871, 0.10055078530376406, 0.8446265965516181, 0.013406771373835209, 0.013406771373835209, 0.026813542747670418, 0.2224622145726592, 0.11248089500864791, 0.48991678714877757, 0.08248598967300846, 0.09248429145155494, 0.08541975880896077, 0.5290514093974344, 0.17083951761792154, 0.0799088066277375, 0.1322628523493586, 0.04800345258048523, 0.03733601867371073, 0.10134062211435771, 0.7573878073809892, 0.058670886487259724, 0.21169273940552275, 0.12540493801740205, 0.21169273940552275, 0.39232187031132204, 0.057525200925413786, 0.05939653172191008, 0.8909479758286513, 0.01979884390730336, 0.018204002134111212, 0.07888400924781525, 0.885928103860079, 0.012136001422740808, 0.18230752164838768, 0.1836480181310964, 0.33110263122905703, 0.20308521713037306, 0.0998669879618006, 0.09342721563876759, 0.8875585485682921, 0.9192364728596767, 0.052527798449124384, 0.043789720825130427, 0.04135695855706763, 0.11677258886701447, 0.7736184012439709, 0.024327622680628016, 0.9695852187481988, 0.8899866775729767, 0.7374262115272484, 0.11679731921704865, 0.025191578654657553, 0.029771865682777107, 0.0916057405623911, 0.4487408165043827, 0.18345580439443882, 0.131039860281742, 0.09314200140889288, 0.14367247990602505, 0.878033756827104, 0.06694564520804998, 0.019127327202299992, 0.06694564520804998, 0.8511660605023497, 0.9108533693056083, 0.02154076509354407, 0.08616306037417629, 0.6175019326815967, 0.14001497310803646, 0.13642484559244578, 0.7895682899295836, 0.11090925811719904, 0.031688359462056864, 0.005281393243676145, 0.06337671892411373, 0.05483548367893644, 0.877367738862983, 0.9391652802382692, 0.9212605580760672, 0.24279116994050678, 0.3074598460461558, 0.15202811575713976, 0.1486245012252635, 0.1486245012252635, 0.11505654210922918, 0.8169014489755272, 0.011505654210922919, 0.046022616843691674, 0.07626941261843281, 0.030507765047373125, 0.8847251863738206, 0.03606517950439942, 0.14168463376728344, 0.1854780660226256, 0.6079558830741616, 0.028336926753456688, 0.9642682890688504, 0.9176537086912799, 0.06838064111072757, 0.05861197809490935, 0.09443040915290951, 0.6610128640703666, 0.11396773518454596, 0.9500417868440509, 0.959411920004335, 0.030297218526452684, 0.005049536421075447, 0.010099072842150895, 0.9391524303814005, 0.22995974274617054, 0.1906983232529219, 0.13180619401304897, 0.29726503330602533, 0.14933361342967783, 0.9138117686784664, 0.011594122053736694, 0.06956473232242016, 0.046376488214946776, 0.8579650319765154, 0.011594122053736694, 0.15592357572932483, 0.6496815655388535, 0.025987262621554142, 0.0433121043692569, 0.12127389223391932, 0.9788048246473853, 0.009093523093678436, 0.05910790010890983, 0.10912227712414123, 0.8002300322437023, 0.022733807734196088, 0.3024040099490917, 0.3619132327904792, 0.12509081536046765, 0.028540137485155243, 0.1827783272985474, 0.3119361331573082, 0.5400685290484739, 0.05121339499597598, 0.009311526362904722, 0.09311526362904723, 0.7111924869082836, 0.12327336439743582, 0.015172106387376717, 0.005689539895266269, 0.1460315239785009, 0.042679049588526474, 0.042679049588526474, 0.896260041359056, 0.021339524794263237, 0.8054139804879704, 0.11457056622652657, 0.010260050706853126, 0.032490160571701565, 0.03933019437627032, 0.062381046685404846, 0.8317472891387313, 0.020793682228468283, 0.10396841114234141, 0.06896863498689738, 0.1592238857104915, 0.6547763000607912, 0.05193934239754001, 0.06471131183955804, 0.9680945606195496, 0.9421827261006746, 0.9412533225033056, 0.6239753720674597, 0.19165735686539775, 0.04900330147126647, 0.01197858480408736, 0.12196377255070766, 0.12212443685404349, 0.12403263117988793, 0.2652390112923757, 0.41089784483183384, 0.07759990258434014, 0.9001710113755832, 0.0818337283068712, 0.9308477950261433, 0.07805411274082692, 0.8976222965195096, 0.03902705637041346, 0.9536664925056021, 0.1719098223411965, 0.4473163744592358, 0.17015564048057205, 0.061396365121855895, 0.1491054581530786, 0.050347927877800173, 0.08391321312966696, 0.772001560792936, 0.10069585575560035, 0.016782642625933392, 0.330183732669897, 0.1992824895404112, 0.06447374661601539, 0.06642749651347041, 0.34190623205462706, 0.3368761280917579, 0.39302214944038416, 0.08649522207761351, 0.019726980473841676, 0.16388568393653086, 0.16770804427440933, 0.5975375503406732, 0.03726845428320207, 0.01490738171328083, 0.18261542598769018, 0.1953184419165791, 0.21704993748938708, 0.20035378845174193, 0.20538913498690475, 0.1820675299819401, 0.9150094360435631, 0.9280269295856607, 0.04419175855169813, 0.04486719347408246, 0.08973438694816492, 0.7515254906908813, 0.033650395105561844, 0.0785175885796443, 0.018850960636049553, 0.037701921272099106, 0.8859951498943289, 0.018850960636049553, 0.037701921272099106, 0.8865599122503474, 0.1189327667323327, 0.8060998634080327, 0.013214751859148078, 0.013214751859148078, 0.039644255577444235, 0.9409184665558462, 0.8933148848297481, 0.7042119234416633, 0.21179305968170323, 0.010589652984085162, 0.0026474132460212905, 0.06883274439655356, 0.9479652377819293, 0.2072884961567577, 0.16693144380765443, 0.22930143380172313, 0.20239673223565427, 0.19383614537372326, 0.04686399714338081, 0.1980381814768673, 0.6258611231406341, 0.07256360848007351, 0.055934448203390004, 0.14733511797788076, 0.7278794634429632, 0.043980632232203214, 0.006597094834830482, 0.0725680431831353, 0.9068651860447983, 0.0647760847174856, 0.08499137655647371, 0.06256309663184871, 0.34586768515342775, 0.37419814400558565, 0.13338924376224348, 0.03722150472077702, 0.02481433648051801, 0.8685017768181303, 0.06203584120129503, 0.012407168240259005, 0.9134027241180339, 0.017565437002269882, 0.017565437002269882, 0.035130874004539764, 0.03285818001129434, 0.03285818001129434, 0.03285818001129434, 0.03285818001129434, 0.8871708603049472, 0.9508830576903174, 0.7832812041717003, 0.027071931019759226, 0.005414386203951845, 0.005414386203951845, 0.1786747447304109, 0.9391407486013078, 0.6221952924037917, 0.14014794952659662, 0.1047259403055887, 0.0277215724338323, 0.1047259403055887, 0.27559136562327, 0.15354182998922744, 0.2641027603864, 0.22450086233460104, 0.0824476375822436, 0.15412366481648737, 0.4492140962334205, 0.13626787438043092, 0.04980825753215751, 0.21051037145666568, 0.15128328106536168, 0.090769968639217, 0.14926617065115685, 0.006051331242614467, 0.6031160138472419, 0.9282097210917203, 0.13134372972115227, 0.17238864525901237, 0.21548580657376545, 0.30715278460831963, 0.17375680911027439, 0.9247767581959011, 0.07706472984965843, 0.020452108376150496, 0.9407969853029228, 0.020452108376150496, 0.9229265102476697, 0.6097681749794266, 0.17178963925501278, 0.03656908162359183, 0.017859318932451823, 0.16413564542681913, 0.7476217517102134, 0.09149217241208904, 0.06535155172292074, 0.047053117240502935, 0.049667179309419766, 0.0184724396832768, 0.0092362198416384, 0.092362198416384, 0.8589684452723713, 0.0184724396832768, 0.08955005242809932, 0.10531590672882103, 0.2850466457570485, 0.4414439204202079, 0.0781986373315797, 0.9106986025669076, 0.029789206626020342, 0.0042556009465743345, 0.008511201893148669, 0.051067211358892015, 0.023113674747305208, 0.023113674747305208, 0.9476606646395135, 0.37133533847841005, 0.14110742862179582, 0.24238070275227128, 0.14718382506962435, 0.09722234316525645, 0.96186170310186, 0.9103180355444567, 0.28508719107348224, 0.21724192204397566, 0.19691118486004944, 0.223866544272446, 0.07698267899981051, 0.012770616556228154, 0.006385308278114077, 0.21071517317776456, 0.7598516850955752, 0.006385308278114077, 0.9528200709463835, 0.9661176776208259, 0.058634012059552806, 0.9088271869230684, 0.9190210820598723, 0.03829254508582801, 0.012764181695276005, 0.012764181695276005, 0.02552836339055201, 0.8568734293249168, 0.8028444084527273, 0.042900082894420544, 0.024514333082526023, 0.012257166541263012, 0.11031449887136711, 0.9249994848608963, 0.09103040489961903, 0.09103040489961903, 0.045515202449809514, 0.022757601224904757, 0.751000840421857, 0.06555799023727374, 0.03277899511863687, 0.8522538730845586, 0.025838744654377473, 0.930194807557589, 0.5281205461796695, 0.1328045068472336, 0.1254479889752294, 0.11886584140554145, 0.0948603620337383, 0.017479487575212154, 0.06991795030084862, 0.8564948911853957, 0.017479487575212154, 0.052438462725636466, 0.919212334133811, 0.014909334838021837, 0.044728004514065514, 0.8796507554432884, 0.05963733935208735, 0.04470844536372181, 0.8941689072744361, 0.04470844536372181, 0.24847027928378018, 0.10908451285629374, 0.09090376071357811, 0.018180752142715622, 0.5333020628529915, 0.04181522947160066, 0.08363045894320131, 0.8572122041678135, 0.02090761473580033, 0.02090761473580033, 0.9699476302576922, 0.39813170276783094, 0.12722253659874297, 0.20106149901683693, 0.1761159036053187, 0.0972878221049211, 0.030960218371116732, 0.8359258960201518, 0.061920436742233464, 0.061920436742233464, 0.8463412723236925, 0.062361988487008926, 0.05345313298886479, 0.008908855498144132, 0.03563542199257653, 0.918071639725999, 0.011203536900693927, 0.8402652675520446, 0.14564597970902105, 0.8881498008081382, 0.9173348877611497, 0.03669339551044599, 0.9318252673306741, 0.04659126336653371, 0.1831907659878174, 0.20460267370067917, 0.2771652498387107, 0.1278766710629245, 0.2069817745576638, 0.2013336513488942, 0.4933780686901473, 0.10398551223514314, 0.006637373121392116, 0.19469627822750207, 0.1407282538133999, 0.1598672963320223, 0.4458271080808509, 0.10807929892869113, 0.1452315579354287, 0.1871808111087364, 0.18996623984547356, 0.2690724159688086, 0.23119058514918336, 0.12311595016378198, 0.012580263111744747, 0.08806184178221323, 0.8931986809338771, 0.012580263111744747, 0.047511235044440533, 0.19796347935183556, 0.6730758297962409, 0.07126685256666081, 0.015837078348146846, 0.18352853598658359, 0.10212474986350215, 0.14504674618294508, 0.47954230370687967, 0.09028419915469031, 0.9179833349337146, 0.97851436569663, 0.21918879584234272, 0.35975552361080165, 0.03097232984728756, 0.023824869113298123, 0.36690298434479107, 0.9542614714502318, 0.12788885903044464, 0.11367898580483968, 0.2893646911395919, 0.39852235364537547, 0.07040346279958822, 0.9367736727941524, 0.9636931962957537, 0.9846760378469803], \"Term\": [\"acrylic\", \"acrylic\", \"acrylic\", \"ai\", \"airline\", \"airline\", \"airline\", \"albeit\", \"alex\", \"alex\", \"alley\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"ami\", \"ami\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"approve\", \"asada\", \"asada\", \"asada\", \"asada\", \"asada\", \"asia\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"atmosphere\", \"atmosphere\", \"atmosphere\", \"atmosphere\", \"atmosphere\", \"aunt\", \"authority\", \"authority\", \"ayce\", \"ayce\", \"ayce\", \"ayce\", \"ayce\", \"bachelorette\", \"bagel\", \"bagel\", \"bagel\", \"bagel\", \"bagel\", \"bao\", \"bar\", \"bar\", \"bar\", \"bar\", \"bar\", \"bath\", \"bath\", \"bath\", \"bath\", \"bath\", \"bathroom\", \"bathroom\", \"bathroom\", \"bathroom\", \"bathroom\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"beef\", \"beef\", \"beef\", \"beef\", \"beef\", \"beer\", \"beer\", \"beer\", \"beer\", \"beer\", \"bike\", \"bike\", \"bike\", \"bike\", \"bike\", \"birthday\", \"birthday\", \"birthday\", \"birthday\", \"birthday\", \"bisque\", \"bisque\", \"bisque\", \"boba\", \"boba\", \"boba\", \"bowl\", \"bowl\", \"bowl\", \"bowl\", \"bowl\", \"bowling\", \"br\", \"bra\", \"bra\", \"bread\", \"bread\", \"bread\", \"bread\", \"bread\", \"breakfast\", \"breakfast\", \"breakfast\", \"breakfast\", \"breakfast\", \"brewery\", \"brewery\", \"brie\", \"brie\", \"britney\", \"broth\", \"broth\", \"broth\", \"broth\", \"broth\", \"buckle\", \"bumper\", \"burger\", \"burger\", \"burger\", \"burger\", \"burger\", \"bus\", \"bus\", \"bus\", \"bus\", \"bus\", \"business\", \"business\", \"business\", \"business\", \"business\", \"buyer\", \"bye\", \"byob\", \"byob\", \"byob\", \"byob\", \"call\", \"call\", \"call\", \"call\", \"call\", \"calzone\", \"campus\", \"campus\", \"campus\", \"cappuccino\", \"cappuccino\", \"cappuccino\", \"cappuccino\", \"cappuccino\", \"car\", \"car\", \"car\", \"car\", \"car\", \"card\", \"card\", \"card\", \"card\", \"card\", \"care\", \"care\", \"care\", \"care\", \"care\", \"carl\", \"carl\", \"carl\", \"carne\", \"carne\", \"carne\", \"carne\", \"carne\", \"casino\", \"casino\", \"casino\", \"casino\", \"casino\", \"cave\", \"certificate\", \"cesar\", \"cha\", \"charge\", \"charge\", \"charge\", \"charge\", \"charge\", \"check\", \"check\", \"check\", \"check\", \"check\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chimichanga\", \"chimichanga\", \"chive\", \"chunky\", \"cirque\", \"client\", \"client\", \"client\", \"client\", \"client\", \"coca\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"cola\", \"come\", \"come\", \"come\", \"come\", \"come\", \"company\", \"company\", \"company\", \"company\", \"company\", \"concoction\", \"coney\", \"consultation\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\", \"cookie\", \"cookie\", \"cookie\", \"cookie\", \"cookie\", \"cox\", \"cox\", \"cream\", \"cream\", \"cream\", \"cream\", \"cream\", \"crust\", \"crust\", \"crust\", \"crust\", \"crust\", \"curly\", \"curly\", \"curry\", \"curry\", \"curry\", \"curry\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"dang\", \"day\", \"day\", \"day\", \"day\", \"day\", \"dealership\", \"dealership\", \"dealership\", \"dealership\", \"dedicated\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delish\", \"delish\", \"delish\", \"delish\", \"delish\", \"dentist\", \"dentist\", \"dentist\", \"dentist\", \"des\", \"des\", \"desk\", \"desk\", \"desk\", \"desk\", \"desk\", \"didn\", \"didn\", \"didn\", \"didn\", \"didn\", \"dim\", \"dim\", \"dim\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"dish\", \"dish\", \"dish\", \"dish\", \"dish\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"dolphin\", \"dolphin\", \"don\", \"don\", \"don\", \"don\", \"don\", \"donut\", \"donut\", \"donut\", \"donut\", \"donut\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dragon\", \"dragon\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"duh\", \"duh\", \"dumpling\", \"dumpling\", \"dumpling\", \"dumpling\", \"earl\", \"earl\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"egg\", \"egg\", \"egg\", \"egg\", \"egg\", \"elevator\", \"elevator\", \"elevator\", \"email\", \"email\", \"email\", \"email\", \"email\", \"enchilada\", \"enchilada\", \"enchilada\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"est\", \"est\", \"est\", \"et\", \"et\", \"et\", \"et\", \"ethic\", \"exam\", \"exam\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"fantastic\", \"fantastic\", \"fantastic\", \"fantastic\", \"fantastic\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"fe\", \"fe\", \"fi\", \"film\", \"find\", \"find\", \"find\", \"find\", \"find\", \"firm\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"fog\", \"food\", \"food\", \"food\", \"food\", \"food\", \"france\", \"freezer\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"fry\", \"fry\", \"fry\", \"fry\", \"fry\", \"gabi\", \"gate\", \"gate\", \"gate\", \"gate\", \"gate\", \"gel\", \"gel\", \"gel\", \"gel\", \"gel\", \"get\", \"get\", \"get\", \"get\", \"get\", \"ginger\", \"ginger\", \"ginger\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gooey\", \"google\", \"google\", \"great\", \"great\", \"great\", \"great\", \"great\", \"grub\", \"gym\", \"gym\", \"gym\", \"gym\", \"gym\", \"hahaha\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"hakka\", \"hangover\", \"hangover\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"heartbeat\", \"hibachi\", \"hire\", \"hire\", \"hire\", \"hire\", \"hire\", \"hk\", \"hop\", \"hop\", \"hop\", \"hop\", \"hop\", \"horribly\", \"horribly\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"hour\", \"hour\", \"hour\", \"hour\", \"hour\", \"howard\", \"humor\", \"ice\", \"ice\", \"ice\", \"ice\", \"ice\", \"ihop\", \"ihop\", \"india\", \"ink\", \"installer\", \"instruct\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"ipa\", \"ipa\", \"jacuzzi\", \"jacuzzi\", \"jambalaya\", \"jambalaya\", \"je\", \"je\", \"josh\", \"jr\", \"keg\", \"kevin\", \"kevin\", \"knife\", \"know\", \"know\", \"know\", \"know\", \"know\", \"lamp\", \"lash\", \"lash\", \"lash\", \"layout\", \"layout\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"lebanese\", \"lentil\", \"like\", \"like\", \"like\", \"like\", \"like\", \"line\", \"line\", \"line\", \"line\", \"line\", \"lion\", \"little\", \"little\", \"little\", \"little\", \"little\", \"lobby\", \"lobby\", \"lobby\", \"lobby\", \"lobby\", \"lobster\", \"lobster\", \"lobster\", \"lobster\", \"lobster\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"love\", \"m\", \"m\", \"m\", \"m\", \"m\", \"macaroon\", \"macaroon\", \"macaroon\", \"mani\", \"mani\", \"mani\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"margarita\", \"margarita\", \"margarita\", \"marsala\", \"meal\", \"meal\", \"meal\", \"meal\", \"meal\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"mercede\", \"mighty\", \"milk\", \"milk\", \"milk\", \"milk\", \"milk\", \"minute\", \"minute\", \"minute\", \"minute\", \"minute\", \"miserable\", \"miserable\", \"miserable\", \"mission\", \"mojito\", \"money\", \"money\", \"money\", \"money\", \"money\", \"mongolian\", \"mongolian\", \"month\", \"month\", \"month\", \"month\", \"month\", \"msg\", \"mug\", \"mule\", \"nail\", \"nail\", \"nail\", \"nail\", \"nail\", \"need\", \"need\", \"need\", \"need\", \"need\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"night\", \"noodle\", \"noodle\", \"noodle\", \"noodle\", \"noodle\", \"northern\", \"office\", \"office\", \"office\", \"office\", \"office\", \"order\", \"order\", \"order\", \"order\", \"order\", \"ou\", \"pancake\", \"pancake\", \"pancake\", \"pancake\", \"pancake\", \"parking\", \"parking\", \"parking\", \"parking\", \"parking\", \"party\", \"party\", \"party\", \"party\", \"party\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pedi\", \"pedi\", \"pedi\", \"pedicure\", \"pedicure\", \"pedicure\", \"pedicure\", \"people\", \"people\", \"people\", \"people\", \"people\", \"peoria\", \"peoria\", \"pepperoni\", \"pepperoni\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"physician\", \"pilot\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"place\", \"place\", \"place\", \"place\", \"place\", \"po\", \"polish\", \"polish\", \"polish\", \"polish\", \"pond\", \"pool\", \"pool\", \"pool\", \"pool\", \"pool\", \"pork\", \"pork\", \"pork\", \"pork\", \"pork\", \"port\", \"port\", \"possibility\", \"pregnancy\", \"price\", \"price\", \"price\", \"price\", \"price\", \"prime\", \"prime\", \"prime\", \"prime\", \"procedure\", \"procedure\", \"procedure\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"promotion\", \"pt\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"queue\", \"raman\", \"raman\", \"raman\", \"raman\", \"recline\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recycle\", \"refer\", \"refer\", \"refer\", \"refer\", \"refer\", \"refill\", \"refill\", \"refill\", \"refill\", \"refill\", \"removal\", \"repair\", \"repair\", \"repair\", \"repair\", \"repair\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"rib\", \"rib\", \"rib\", \"rib\", \"rib\", \"rice\", \"rice\", \"rice\", \"rice\", \"rice\", \"robert\", \"robert\", \"robert\", \"robert\", \"roll\", \"roll\", \"roll\", \"roll\", \"roll\", \"roof\", \"roof\", \"roof\", \"roof\", \"room\", \"room\", \"room\", \"room\", \"room\", \"roti\", \"sammie\", \"satisfying\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scorpion\", \"scorpion\", \"scott\", \"scramble\", \"scramble\", \"scramble\", \"scrumptious\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"security\", \"security\", \"security\", \"security\", \"security\", \"selection\", \"selection\", \"selection\", \"selection\", \"selection\", \"serve\", \"serve\", \"serve\", \"serve\", \"serve\", \"server\", \"server\", \"server\", \"server\", \"server\", \"service\", \"service\", \"service\", \"service\", \"service\", \"sever\", \"shawarma\", \"shawarma\", \"shopping\", \"shopping\", \"shopping\", \"shopping\", \"shopping\", \"shower\", \"shower\", \"shower\", \"shower\", \"shower\", \"showroom\", \"slider\", \"slider\", \"slider\", \"slider\", \"slider\", \"sont\", \"soothe\", \"spicy\", \"spicy\", \"spicy\", \"spicy\", \"spicy\", \"spider\", \"staff\", \"staff\", \"staff\", \"staff\", \"staff\", \"stay\", \"stay\", \"stay\", \"stay\", \"stay\", \"steak\", \"steak\", \"steak\", \"steak\", \"steak\", \"storage\", \"storage\", \"store\", \"store\", \"store\", \"store\", \"store\", \"stylist\", \"stylist\", \"stylist\", \"stylist\", \"stylist\", \"sum\", \"sum\", \"sum\", \"sum\", \"summerlin\", \"summerlin\", \"summerlin\", \"summerlin\", \"summerlin\", \"sur\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"suzi\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"t\", \"t\", \"t\", \"t\", \"t\", \"table\", \"table\", \"table\", \"table\", \"table\", \"taco\", \"taco\", \"taco\", \"taco\", \"taco\", \"tai\", \"take\", \"take\", \"take\", \"take\", \"take\", \"talented\", \"talented\", \"tan\", \"tan\", \"tan\", \"tapioca\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tea\", \"tea\", \"tea\", \"tea\", \"tea\", \"tech\", \"tech\", \"tech\", \"tech\", \"tech\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"thai\", \"thai\", \"thai\", \"thai\", \"thai\", \"therapist\", \"therapist\", \"therapist\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thread\", \"thrifty\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tire\", \"tire\", \"tire\", \"tire\", \"tire\", \"tj\", \"toasted\", \"toe\", \"toe\", \"tofu\", \"tofu\", \"tofu\", \"tofu\", \"tofu\", \"tomatillo\", \"topping\", \"topping\", \"topping\", \"topping\", \"topping\", \"torta\", \"toss\", \"toss\", \"toss\", \"toss\", \"toss\", \"tot\", \"tot\", \"tot\", \"tow\", \"tow\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tub\", \"tub\", \"tub\", \"tub\", \"tub\", \"tube\", \"un\", \"un\", \"un\", \"un\", \"unfriendly\", \"unfriendly\", \"unfriendly\", \"unique\", \"unique\", \"unique\", \"unique\", \"unique\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"urban\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"veal\", \"veal\", \"veal\", \"veal\", \"vegan\", \"vegan\", \"vegan\", \"vegan\", \"vegan\", \"verify\", \"vet\", \"vet\", \"vet\", \"volcano\", \"vous\", \"vous\", \"wagyu\", \"wagyu\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"waitress\", \"waitress\", \"waitress\", \"waitress\", \"waitress\", \"walk\", \"walk\", \"walk\", \"walk\", \"walk\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warranty\", \"warranty\", \"warranty\", \"warranty\", \"wedding\", \"wedding\", \"wedding\", \"wedding\", \"wedding\", \"week\", \"week\", \"week\", \"week\", \"week\", \"wheat\", \"wi\", \"wine\", \"wine\", \"wine\", \"wine\", \"wine\", \"wonton\", \"work\", \"work\", \"work\", \"work\", \"work\", \"xs\", \"yellowtail\", \"yuk\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 5, 2, 4]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el47781399920739284801196979540\", ldavis_el47781399920739284801196979540_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el47781399920739284801196979540\", ldavis_el47781399920739284801196979540_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el47781399920739284801196979540\", ldavis_el47781399920739284801196979540_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "2     -0.093411  0.007789       1        1  27.189197\n",
              "0     -0.048884 -0.016516       2        1  20.001085\n",
              "4      0.058293 -0.052635       3        1  19.757076\n",
              "1      0.133071  0.032939       4        1  19.392664\n",
              "3     -0.049069  0.028423       5        1  13.659978, topic_info=           Term         Freq        Total Category  logprob  loglift\n",
              "135        food  4756.000000  4756.000000  Default  30.0000  30.0000\n",
              "194       great  4193.000000  4193.000000  Default  29.0000  29.0000\n",
              "724         car   739.000000   739.000000  Default  28.0000  28.0000\n",
              "821      burger   682.000000   682.000000  Default  27.0000  27.0000\n",
              "357       order  3436.000000  3436.000000  Default  26.0000  26.0000\n",
              "..          ...          ...          ...      ...      ...      ...\n",
              "253  experience   259.573654  1452.038973   Topic5  -5.5696   0.2690\n",
              "377        take   253.886487  1461.813216   Topic5  -5.5918   0.2402\n",
              "145       price   261.633758  1762.831820   Topic5  -5.5617   0.0830\n",
              "16         like   327.175840  3778.734264   Topic5  -5.3382  -0.4559\n",
              "32         time   336.625708  4377.608111   Topic5  -5.3097  -0.5746\n",
              "\n",
              "[485 rows x 6 columns], token_table=       Topic      Freq        Term\n",
              "term                              \n",
              "8970       2  0.089997     acrylic\n",
              "8970       3  0.869967     acrylic\n",
              "8970       4  0.029999     acrylic\n",
              "8090       4  0.955609          ai\n",
              "9374       1  0.037394     airline\n",
              "...      ...       ...         ...\n",
              "306        4  0.398522        work\n",
              "306        5  0.070403        work\n",
              "2931       2  0.936774          xs\n",
              "8509       1  0.963693  yellowtail\n",
              "10515      5  0.984676         yuk\n",
              "\n",
              "[1247 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 5, 2, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9oc9kzWyKkXW",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f44a26c754500ff0bf585296075bf754",
          "grade": false,
          "grade_id": "cell-bf9e63d9645bba84",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        }
      },
      "source": [
        "#### 3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XpdEFekc64V"
      },
      "source": [
        "The first topic is about food restaurant. There are rice, noogle, sushi, pork words inside it. Topic 2 and 5 are also restaurants topic. Not only they are very close to each other and to topic one on the axis. They have words like bread, pancake, cappuccino. Topic 5 gears more toward drinking store with brew, beer, mojito. Words like mojito only appear in topic 5. Topic 3 is about personal store like gym, hair, airline while topic 4 is for office/company. Words in topic 4 is car, insurance, phone, doctor, tech."
      ]
    }
  ]
}